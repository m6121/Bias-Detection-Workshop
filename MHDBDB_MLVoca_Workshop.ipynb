{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üì¶ Setup und MHDBDB-Daten laden\n",
        "print(\"üöÄ MHDBDB Workshop Setup - MLVoca.com\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# MHDBDB-Daten direkt von GitHub laden\n",
        "def load_mhdbdb_data():\n",
        "    \"\"\"L√§dt kuratierte MHDBDB Bias-Daten f√ºr Workshop\"\"\"\n",
        "    \n",
        "    bias_terms = {\n",
        "        \"ethnisch_religi√∂s\": [\n",
        "            {\"word\": \"saraz√Æn\", \"meaning\": \"Angeh√∂riger eines islamischen Volkes; Heide\", \"source\": \"Parzival\", \"author\": \"Wolfram von Eschenbach\"},\n",
        "            {\"word\": \"heiden\", \"meaning\": \"Nicht-Christ; Anh√§nger einer anderen Religion\", \"source\": \"Rolandslied\", \"author\": \"Pfaffe Konrad\"},\n",
        "            {\"word\": \"jude\", \"meaning\": \"Angeh√∂riger der j√ºdischen Religion\", \"source\": \"Marienleben\", \"author\": \"Bruder Philipp\"}\n",
        "        ],\n",
        "        \"geschlecht_stand\": [\n",
        "            {\"word\": \"vrouwe\", \"meaning\": \"Herrin, edle Dame; Ehefrau\", \"source\": \"Iwein\", \"author\": \"Hartmann von Aue\"},\n",
        "            {\"word\": \"w√Æp\", \"meaning\": \"Frau; Ehefrau\", \"source\": \"Nibelungenlied\", \"author\": \"unbekannt\"},\n",
        "            {\"word\": \"maget\", \"meaning\": \"Jungfrau; unverheiratete Frau\", \"source\": \"Kudrun\", \"author\": \"unbekannt\"}\n",
        "        ],\n",
        "        \"sozialer_stand\": [\n",
        "            {\"word\": \"ritter\", \"meaning\": \"Angeh√∂riger des Ritterstandes; Krieger zu Pferde\", \"source\": \"Erec\", \"author\": \"Hartmann von Aue\"},\n",
        "            {\"word\": \"b√ªr\", \"meaning\": \"Bauer, Landmann\", \"source\": \"Meier Helmbrecht\", \"author\": \"Wernher der G√§rtner\"},\n",
        "            {\"word\": \"pfaffe\", \"meaning\": \"Geistlicher, Priester\", \"source\": \"Der arme Heinrich\", \"author\": \"Hartmann von Aue\"}\n",
        "        ],\n",
        "        \"behinderung_fremdheit\": [\n",
        "            {\"word\": \"kr√ºppel\", \"meaning\": \"k√∂rperlich beeintr√§chtigte Person\", \"source\": \"Gregorius\", \"author\": \"Hartmann von Aue\"},\n",
        "            {\"word\": \"blint\", \"meaning\": \"blind; ohne Sehverm√∂gen\", \"source\": \"Gregorius\", \"author\": \"Hartmann von Aue\"},\n",
        "            {\"word\": \"ellende\", \"meaning\": \"Fremde, Verbannung; Elend\", \"source\": \"Kudrun\", \"author\": \"unbekannt\"}\n",
        "        ]\n",
        "    }\n",
        "    \n",
        "    # DataFrame erstellen\n",
        "    all_terms = []\n",
        "    for category, terms in bias_terms.items():\n",
        "        for term in terms:\n",
        "            term['bias_category'] = category\n",
        "            all_terms.append(term)\n",
        "    \n",
        "    return pd.DataFrame(all_terms)\n",
        "\n",
        "# Daten laden\n",
        "df = load_mhdbdb_data()\n",
        "\n",
        "print(f\"‚úÖ {len(df)} MHDBDB-Begriffe geladen\")\n",
        "print(f\"üìÇ {df['bias_category'].nunique()} Bias-Kategorien verf√ºgbar\")\n",
        "print(f\"üìö {df['source'].nunique()} verschiedene Quellentexte\")\n",
        "\n",
        "print(\"\\nüìä Verf√ºgbare Bias-Kategorien:\")\n",
        "for category in df['bias_category'].unique():\n",
        "    count = len(df[df['bias_category'] == category])\n",
        "    print(f\"   ‚Ä¢ {category.replace('_', ' ').title()}: {count} Begriffe\")\n",
        "\n",
        "print(\"\\nüéØ Workshop-Daten bereit!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîë MLVoca.com API-Setup\n",
        "\n",
        "class MLVoca_BiasLab:\n",
        "    \"\"\"MLVoca.com API Interface - Kostenlose LLM API ohne API-Key\"\"\"\n",
        "    \n",
        "    BASE_URL = \"https://mlvoca.com/api/generate\"\n",
        "    \n",
        "    MODELS = {\n",
        "        \"tinyllama\": \"TinyLlama (Fast & Compact)\",\n",
        "        \"deepseek-r1:1.5b\": \"DeepSeek R1 1.5B (Reasoning)\"\n",
        "    }\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.selected_model = \"tinyllama\"\n",
        "        self.test_results = []\n",
        "        self.api_available = False\n",
        "        \n",
        "    def test_api(self):\n",
        "        \"\"\"Testet die MLVoca API-Verf√ºgbarkeit\"\"\"\n",
        "        try:\n",
        "            response = requests.post(\n",
        "                self.BASE_URL,\n",
        "                json={\n",
        "                    \"model\": \"tinyllama\",\n",
        "                    \"prompt\": \"Test\",\n",
        "                    \"stream\": False\n",
        "                },\n",
        "                timeout=10\n",
        "            )\n",
        "            \n",
        "            if response.status_code == 200:\n",
        "                self.api_available = True\n",
        "                return True, \"MLVoca.com API verf√ºgbar! Keine Konfiguration n√∂tig.\"\n",
        "            else:\n",
        "                self.api_available = False\n",
        "                return False, f\"API-Fehler: {response.status_code}\"\n",
        "                \n",
        "        except Exception as e:\n",
        "            self.api_available = False\n",
        "            return False, f\"Verbindungsfehler: {str(e)}\"\n",
        "    \n",
        "    def send_prompt(self, prompt, system_message=\"Du bist Experte f√ºr mittelhochdeutsche Literatur.\"):\n",
        "        \"\"\"Sendet Prompt an MLVoca API\"\"\"\n",
        "        if not self.api_available:\n",
        "            return \"API nicht verf√ºgbar. Bitte testen Sie die API zuerst.\"\n",
        "        \n",
        "        try:\n",
        "            # Kombiniere System-Message mit Prompt\n",
        "            full_prompt = f\"{system_message}\\n\\n{prompt}\"\n",
        "            \n",
        "            response = requests.post(\n",
        "                self.BASE_URL,\n",
        "                json={\n",
        "                    \"model\": self.selected_model,\n",
        "                    \"prompt\": full_prompt,\n",
        "                    \"stream\": False\n",
        "                },\n",
        "                timeout=30\n",
        "            )\n",
        "            \n",
        "            if response.status_code == 200:\n",
        "                result = response.json()\n",
        "                return result.get('response', 'Keine Antwort erhalten')\n",
        "            else:\n",
        "                return f\"API-Fehler: {response.status_code}\"\n",
        "                \n",
        "        except Exception as e:\n",
        "            return f\"Fehler: {str(e)}\"\n",
        "    \n",
        "    def set_model(self, model_name):\n",
        "        \"\"\"√Ñndert das verwendete Modell\"\"\"\n",
        "        if model_name in self.MODELS:\n",
        "            self.selected_model = model_name\n",
        "            return True, f\"Modell ge√§ndert zu: {self.MODELS[model_name]}\"\n",
        "        else:\n",
        "            return False, f\"Unbekanntes Modell: {model_name}\"\n",
        "\n",
        "# Lab-Instanz erstellen\n",
        "bias_lab = MLVoca_BiasLab()\n",
        "\n",
        "# API-Test Interface\n",
        "def create_api_setup():\n",
        "    \"\"\"Erstellt MLVoca API-Test Interface\"\"\"\n",
        "    \n",
        "    model_selector = widgets.Dropdown(\n",
        "        options=[(name, key) for key, name in bias_lab.MODELS.items()],\n",
        "        value=\"tinyllama\",\n",
        "        description='Modell:',\n",
        "        layout=widgets.Layout(width='350px')\n",
        "    )\n",
        "    \n",
        "    test_button = widgets.Button(\n",
        "        description='üîß API testen',\n",
        "        button_style='success',\n",
        "        icon='check'\n",
        "    )\n",
        "    \n",
        "    status_output = widgets.Output()\n",
        "    \n",
        "    def test_api(button):\n",
        "        with status_output:\n",
        "            clear_output(wait=True)\n",
        "            \n",
        "            selected_model = model_selector.value\n",
        "            bias_lab.set_model(selected_model)\n",
        "            \n",
        "            print(f\"üîÑ Teste {bias_lab.MODELS[selected_model]}...\")\n",
        "            \n",
        "            success, message = bias_lab.test_api()\n",
        "            print(message)\n",
        "            \n",
        "            if success:\n",
        "                print(\"\\\\nüöÄ Bereit f√ºr Prompt-Training!\")\n",
        "                print(\"üí° Kein API-Key erforderlich - v√∂llig kostenlos!\")\n",
        "    \n",
        "    test_button.on_click(test_api)\n",
        "    \n",
        "    return widgets.VBox([\n",
        "        widgets.HTML(\"<h3>üîë MLVoca.com API-Test</h3>\"),\n",
        "        widgets.HTML(\"<p>Kostenlose LLM API - kein API-Key erforderlich!</p>\"),\n",
        "        widgets.HTML(\"<p>Mehr Info: <a href='https://mlvoca.github.io/free-llm-api/' target='_blank'>mlvoca.github.io/free-llm-api</a></p>\"),\n",
        "        model_selector,\n",
        "        test_button,\n",
        "        status_output\n",
        "    ])\n",
        "\n",
        "# Setup-Widget anzeigen\n",
        "setup_widget = create_api_setup()\n",
        "display(setup_widget)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ‚úçÔ∏è Haupttool: Freie Prompt-Erstellung\n",
        "\n",
        "def create_prompt_training_interface():\n",
        "    \"\"\"Hauptinterface f√ºr selbstst√§ndige Prompt-Erstellung mit MLVoca\"\"\"\n",
        "    \n",
        "    # Begriff-Auswahl nach Kategorien\n",
        "    category_selector = widgets.Dropdown(\n",
        "        options=[(cat.replace('_', ' ').title(), cat) for cat in df['bias_category'].unique()],\n",
        "        description='Kategorie:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "    \n",
        "    term_selector = widgets.Dropdown(\n",
        "        options=[],\n",
        "        description='Begriff:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "    \n",
        "    # Info-Bereich f√ºr gew√§hlten Begriff\n",
        "    term_info = widgets.HTML()\n",
        "    \n",
        "    # Gro√üer Prompt-Editor\n",
        "    prompt_editor = widgets.Textarea(\n",
        "        placeholder='Schreiben Sie hier Ihren Prompt f√ºr MLVoca...\\\\n\\\\nTipps:\\\\n- Seien Sie spezifisch\\\\n- Fragen Sie nach historischem Kontext\\\\n- Experimentieren Sie mit verschiedenen Modellen',\n",
        "        description='Ihr Prompt:',\n",
        "        layout=widgets.Layout(width='100%', height='150px'),\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "    \n",
        "    # Prompt-Beispiele als Inspiration\n",
        "    example_prompts = {\n",
        "        'Historisch neutral': 'Erkl√§re die Bedeutung des mittelhochdeutschen Begriffs \"{word}\" im historischen Kontext des 12.-13. Jahrhunderts.',\n",
        "        'Kritisch-analytisch': 'Analysiere den Begriff \"{word}\" aus der mittelalterlichen Literatur. Welche gesellschaftlichen Strukturen und Wertvorstellungen spiegelt er wider?',\n",
        "        'Bias-fokussiert': 'Untersuche den Begriff \"{word}\" auf m√∂gliche Vorurteile oder Stereotypen. Wie k√∂nnte dieser Begriff heute problematisch wirken?',\n",
        "        'Vergleichend': 'Vergleiche die mittelalterliche Verwendung von \"{word}\" mit modernen Begriffen. Was hat sich in der Bedeutung ver√§ndert?',\n",
        "        'Sprachwissenschaftlich': 'Erkl√§re die etymologische Entwicklung von \"{word}\" und analysiere seine semantischen Ver√§nderungen √ºber die Zeit.'\n",
        "    }\n",
        "    \n",
        "    example_selector = widgets.Dropdown(\n",
        "        options=[('--- Beispiel w√§hlen ---', '')] + list(example_prompts.items()),\n",
        "        description='Beispiele:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "    \n",
        "    # Modell-Wechsel Button\n",
        "    model_button = widgets.Button(\n",
        "        description='ü§ñ Modell wechseln',\n",
        "        button_style='info',\n",
        "        icon='refresh'\n",
        "    )\n",
        "    \n",
        "    # Sende-Button\n",
        "    send_button = widgets.Button(\n",
        "        description='üöÄ Prompt senden',\n",
        "        button_style='primary',\n",
        "        icon='paper-plane'\n",
        "    )\n",
        "    \n",
        "    # Ergebnis-Bereich\n",
        "    result_output = widgets.Output()\n",
        "    \n",
        "    # Event-Handler\n",
        "    def update_terms(change):\n",
        "        \"\"\"Aktualisiert Begriffe basierend auf Kategorie\"\"\"\n",
        "        category = change['new']\n",
        "        filtered_df = df[df['bias_category'] == category]\n",
        "        \n",
        "        options = [(f\"{row['word']} ({row['source']})\", idx) \n",
        "                  for idx, row in filtered_df.iterrows()]\n",
        "        \n",
        "        term_selector.options = options\n",
        "        if options:\n",
        "            term_selector.value = options[0][1]\n",
        "    \n",
        "    def update_term_info(change):\n",
        "        \"\"\"Zeigt Info zum gew√§hlten Begriff\"\"\"\n",
        "        if change['new'] is not None:\n",
        "            term_data = df.iloc[change['new']]\n",
        "            \n",
        "            info_html = f\"\"\"\n",
        "            <div style='background: #f0f8ff; padding: 10px; border-radius: 5px; margin: 10px 0;'>\n",
        "                <h4>üìö Begriff: {term_data['word']}</h4>\n",
        "                <p><strong>Bedeutung:</strong> {term_data['meaning']}</p>\n",
        "                <p><strong>Quelle:</strong> {term_data['source']} ({term_data['author']})</p>\n",
        "                <p><strong>Bias-Kategorie:</strong> {term_data['bias_category'].replace('_', ' ').title()}</p>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "            \n",
        "            term_info.value = info_html\n",
        "    \n",
        "    def load_example(change):\n",
        "        \"\"\"L√§dt Beispiel-Prompt\"\"\"\n",
        "        if change['new'] and change['new'][1]:\n",
        "            if term_selector.value is not None:\n",
        "                term_data = df.iloc[term_selector.value]\n",
        "                example_prompt = change['new'][1].format(word=term_data['word'])\n",
        "                prompt_editor.value = example_prompt\n",
        "    \n",
        "    def show_model_options(button):\n",
        "        \"\"\"Zeigt Modell-Wechsel-Optionen\"\"\"\n",
        "        with result_output:\n",
        "            clear_output(wait=True)\n",
        "            \n",
        "            print(\"ü§ñ Verf√ºgbare MLVoca Modelle:\")\n",
        "            for key, name in bias_lab.MODELS.items():\n",
        "                current = \" ‚Üê AKTIV\" if key == bias_lab.selected_model else \"\"\n",
        "                print(f\"‚Ä¢ {name}{current}\")\n",
        "            \n",
        "            print(\"\\\\nüí° Modell wechseln:\")\n",
        "            \n",
        "            # Modell-Wechsel Interface\n",
        "            model_dropdown = widgets.Dropdown(\n",
        "                options=[(name, key) for key, name in bias_lab.MODELS.items()],\n",
        "                value=bias_lab.selected_model,\n",
        "                description='Neues Modell:'\n",
        "            )\n",
        "            \n",
        "            change_button = widgets.Button(\n",
        "                description='Modell setzen',\n",
        "                button_style='warning'\n",
        "            )\n",
        "            \n",
        "            def change_model(button):\n",
        "                success, message = bias_lab.set_model(model_dropdown.value)\n",
        "                print(f\"\\\\n{message}\")\n",
        "            \n",
        "            change_button.on_click(change_model)\n",
        "            display(widgets.HBox([model_dropdown, change_button]))\n",
        "    \n",
        "    def send_prompt(button):\n",
        "        \"\"\"Sendet Prompt an MLVoca\"\"\"\n",
        "        with result_output:\n",
        "            clear_output(wait=True)\n",
        "            \n",
        "            if not bias_lab.api_available:\n",
        "                print(\"API nicht verf√ºgbar! Bitte testen Sie die API zuerst.\")\n",
        "                return\n",
        "            \n",
        "            prompt = prompt_editor.value.strip()\n",
        "            if not prompt:\n",
        "                print(\"Prompt eingeben!\")\n",
        "                return\n",
        "            \n",
        "            term_data = df.iloc[term_selector.value]\n",
        "            \n",
        "            print(f\"üß™ Test: '{term_data['word']}'\")\n",
        "            print(f\"ü§ñ {bias_lab.MODELS[bias_lab.selected_model]}\")\n",
        "            print(f\"üìù Prompt: {prompt}\")\n",
        "            print(\"\\\\n\" + \"=\"*50)\n",
        "            print(\"üîÑ MLVoca antwortet...\")\n",
        "            \n",
        "            response = bias_lab.send_prompt(prompt)\n",
        "            print(response)\n",
        "            \n",
        "            # Ergebnis speichern\n",
        "            bias_lab.test_results.append({\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'term': term_data['word'],\n",
        "                'category': term_data['bias_category'],\n",
        "                'model': bias_lab.selected_model,\n",
        "                'prompt': prompt,\n",
        "                'response': response\n",
        "            })\n",
        "            \n",
        "            print(\"\\\\n\" + \"=\"*50)\n",
        "            print(f\"‚úÖ Test #{len(bias_lab.test_results)} gespeichert!\")\n",
        "    \n",
        "    # Event-Bindings\n",
        "    category_selector.observe(update_terms, names='value')\n",
        "    term_selector.observe(update_term_info, names='value')\n",
        "    example_selector.observe(load_example, names='value')\n",
        "    model_button.on_click(show_model_options)\n",
        "    send_button.on_click(send_prompt)\n",
        "    \n",
        "    # Initial Setup\n",
        "    if category_selector.options:\n",
        "        category_selector.value = category_selector.options[0][1]\n",
        "    \n",
        "    # Layout\n",
        "    return widgets.VBox([\n",
        "        widgets.HTML(\"<h3>‚úçÔ∏è Prompt-Training mit MLVoca.com</h3>\"),\n",
        "        widgets.HTML(\"<p>Kostenlose LLM API - experimentieren Sie mit verschiedenen Modellen!</p>\"),\n",
        "        widgets.HBox([category_selector, term_selector]),\n",
        "        term_info,\n",
        "        example_selector,\n",
        "        prompt_editor,\n",
        "        widgets.HBox([model_button, send_button]),\n",
        "        result_output\n",
        "    ])\n",
        "\n",
        "# Interface erstellen und anzeigen\n",
        "prompt_interface = create_prompt_training_interface()\n",
        "display(prompt_interface)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìä Ihre Test-Ergebnisse analysieren\n",
        "\n",
        "def analyze_results():\n",
        "    \"\"\"Analysiert die bisherigen Test-Ergebnisse\"\"\"\n",
        "    \n",
        "    if not bias_lab.test_results:\n",
        "        print(\"üì≠ Noch keine Tests durchgef√ºhrt.\")\n",
        "        print(\"Verwenden Sie das Tool oben, um Prompts zu testen!\")\n",
        "        return\n",
        "    \n",
        "    print(f\"üìä Analyse von {len(bias_lab.test_results)} Tests\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Statistiken\n",
        "    categories = [r['category'] for r in bias_lab.test_results]\n",
        "    terms = [r['term'] for r in bias_lab.test_results]\n",
        "    \n",
        "    print(f\"üè∑Ô∏è Getestete Kategorien: {len(set(categories))}\")\n",
        "    print(f\"üìö Getestete Begriffe: {len(set(terms))}\")\n",
        "    \n",
        "    # Letzte Tests anzeigen\n",
        "    print(f\"\\\\nüìã Ihre letzten {min(3, len(bias_lab.test_results))} Tests:\")\n",
        "    for i, result in enumerate(bias_lab.test_results[-3:], 1):\n",
        "        timestamp = datetime.fromisoformat(result['timestamp']).strftime('%H:%M')\n",
        "        print(f\"\\\\n{i}. {timestamp} - '{result['term']}' ({result['category']})\")\n",
        "        print(f\"   Prompt: {result['prompt'][:60]}...\")\n",
        "        print(f\"   Antwort: {result['response'][:80]}...\")\n",
        "    \n",
        "    print(f\"\\\\nüí° Reflexionsfragen:\")\n",
        "    print(f\"   ‚Ä¢ Welche Prompts erzeugen neutralere Antworten?\")\n",
        "    print(f\"   ‚Ä¢ Wo erkennen Sie potentielle Bias-Muster?\")\n",
        "    print(f\"   ‚Ä¢ Wie beeinflusst Ihre Prompt-Formulierung die Antwort?\")\n",
        "\n",
        "def export_results():\n",
        "    \"\"\"Exportiert Ergebnisse als JSON\"\"\"\n",
        "    \n",
        "    if not bias_lab.test_results:\n",
        "        print(\"‚ùå Keine Ergebnisse zum Exportieren vorhanden.\")\n",
        "        return\n",
        "    \n",
        "    filename = f\"mhdbdb_mlvoca_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "    \n",
        "    export_data = {\n",
        "        'metadata': {\n",
        "            'workshop': 'MHDBDB Bias Detection - MLVoca.com',\n",
        "            'api_provider': 'MLVoca.com (Free LLM API)',\n",
        "            'api_url': 'https://mlvoca.com/api/generate',\n",
        "            'export_time': datetime.now().isoformat(),\n",
        "            'total_tests': len(bias_lab.test_results),\n",
        "            'models_used': list(set(r.get('model', 'unknown') for r in bias_lab.test_results))\n",
        "        },\n",
        "        'results': bias_lab.test_results\n",
        "    }\n",
        "    \n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        json.dump(export_data, f, indent=2, ensure_ascii=False)\n",
        "    \n",
        "    print(f\"‚úÖ Ergebnisse exportiert: {filename}\")\n",
        "\n",
        "# Analyse-Buttons\n",
        "analyze_button = widgets.Button(\n",
        "    description='üìä Ergebnisse analysieren',\n",
        "    button_style='info'\n",
        ")\n",
        "\n",
        "export_button = widgets.Button(\n",
        "    description='üíæ Ergebnisse exportieren',\n",
        "    button_style='success'\n",
        ")\n",
        "\n",
        "analysis_output = widgets.Output()\n",
        "\n",
        "def on_analyze(button):\n",
        "    with analysis_output:\n",
        "        clear_output(wait=True)\n",
        "        analyze_results()\n",
        "\n",
        "def on_export(button):\n",
        "    with analysis_output:\n",
        "        clear_output(wait=True)\n",
        "        export_results()\n",
        "\n",
        "analyze_button.on_click(on_analyze)\n",
        "export_button.on_click(on_export)\n",
        "\n",
        "display(widgets.VBox([\n",
        "    widgets.HTML(\"<h3>üìà Ergebnisse & Export</h3>\"),\n",
        "    widgets.HBox([analyze_button, export_button]),\n",
        "    analysis_output\n",
        "]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîç Bias-Analyse & Reflexions-Tools\n",
        "\n",
        "class BiasAnalyzer:\n",
        "    \"\"\"Erweiterte Analyse-Tools f√ºr Bias-Erkennung\"\"\"\n",
        "    \n",
        "    BIAS_INDICATORS = {\n",
        "        'anachronismus': [\n",
        "            'people of color', 'transgender', 'lgbtq', 'diversity', 'inclusion',\n",
        "            'feminismus', 'gleichberechtigung', 'menschenrechte', 'diskriminierung'\n",
        "        ],\n",
        "        'essentialisierung': [\n",
        "            'typisch f√ºr', 'charakteristisch', 'nat√ºrlich', 'von natur aus',\n",
        "            'genetisch bedingt', 'instinktiv', 'angeboren'\n",
        "        ],\n",
        "        'stereotypisierung': [\n",
        "            'alle', 'immer', 'nie', 'grunds√§tzlich', 'ausnahmslos',\n",
        "            'typischerweise', 'normalerweise', '√ºblicherweise'\n",
        "        ],\n",
        "        'modernisierung': [\n",
        "            'fortschrittlich', 'r√ºckst√§ndig', 'entwickelt', 'primitiv',\n",
        "            'zivilisiert', 'barbarisch', 'aufgekl√§rt', 'modern'\n",
        "        ],\n",
        "        'quantifizierung_unbelegt': [\n",
        "            'millionen', 'tausende', 'die meisten', 'viele', 'h√§ufig',\n",
        "            'selten', 'prozent', 'statistik', 'studie zeigt'\n",
        "        ]\n",
        "    }\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.analyses = []\n",
        "    \n",
        "    def analyze_response(self, response_text, term_info):\n",
        "        \"\"\"Analysiert eine LLM-Antwort auf Bias-Indikatoren\"\"\"\n",
        "        \n",
        "        response_lower = response_text.lower()\n",
        "        detected_bias = {}\n",
        "        \n",
        "        for bias_type, indicators in self.BIAS_INDICATORS.items():\n",
        "            found_indicators = []\n",
        "            for indicator in indicators:\n",
        "                if indicator in response_lower:\n",
        "                    found_indicators.append(indicator)\n",
        "            \n",
        "            if found_indicators:\n",
        "                detected_bias[bias_type] = found_indicators\n",
        "        \n",
        "        analysis = {\n",
        "            'term': term_info.get('word', 'unknown'),\n",
        "            'category': term_info.get('bias_category', 'unknown'),\n",
        "            'response_length': len(response_text),\n",
        "            'detected_bias': detected_bias,\n",
        "            'bias_score': len(detected_bias),\n",
        "            'timestamp': datetime.now().isoformat()\n",
        "        }\n",
        "        \n",
        "        self.analyses.append(analysis)\n",
        "        return analysis\n",
        "    \n",
        "    def generate_reflection_questions(self, analysis):\n",
        "        \"\"\"Generiert spezifische Reflexionsfragen basierend auf der Analyse\"\"\"\n",
        "        \n",
        "        questions = []\n",
        "        \n",
        "        if 'anachronismus' in analysis['detected_bias']:\n",
        "            questions.append(\"üïê Werden moderne Begriffe auf mittelalterliche Verh√§ltnisse √ºbertragen?\")\n",
        "        \n",
        "        if 'essentialisierung' in analysis['detected_bias']:\n",
        "            questions.append(\"üß¨ Werden kulturelle Eigenschaften als 'nat√ºrlich' oder unver√§nderlich dargestellt?\")\n",
        "        \n",
        "        if 'stereotypisierung' in analysis['detected_bias']:\n",
        "            questions.append(\"üè∑Ô∏è Werden Gruppen durch Verallgemeinerungen charakterisiert?\")\n",
        "        \n",
        "        if 'modernisierung' in analysis['detected_bias']:\n",
        "            questions.append(\"üìà Wird eine lineare Fortschrittserz√§hlung impliziert?\")\n",
        "        \n",
        "        if 'quantifizierung_unbelegt' in analysis['detected_bias']:\n",
        "            questions.append(\"üìä Werden unbest√§tigte Zahlen oder Statistiken pr√§sentiert?\")\n",
        "        \n",
        "        if not questions:\n",
        "            questions.append(\"üí≠ Welche impliziten Annahmen enth√§lt diese Antwort?\")\n",
        "            questions.append(\"üîç Wie neutral ist die Darstellung des historischen Kontexts?\")\n",
        "        \n",
        "        return questions\n",
        "    \n",
        "    def get_summary_stats(self):\n",
        "        \"\"\"Erstellt Zusammenfassung der Bias-Analysen\"\"\"\n",
        "        \n",
        "        if not self.analyses:\n",
        "            return None\n",
        "        \n",
        "        total_analyses = len(self.analyses)\n",
        "        biased_responses = len([a for a in self.analyses if a['bias_score'] > 0])\n",
        "        \n",
        "        bias_types_count = {}\n",
        "        for analysis in self.analyses:\n",
        "            for bias_type in analysis['detected_bias'].keys():\n",
        "                bias_types_count[bias_type] = bias_types_count.get(bias_type, 0) + 1\n",
        "        \n",
        "        return {\n",
        "            'total_analyses': total_analyses,\n",
        "            'biased_responses': biased_responses,\n",
        "            'bias_rate': biased_responses / total_analyses * 100,\n",
        "            'most_common_bias': max(bias_types_count.items(), key=lambda x: x[1]) if bias_types_count else None,\n",
        "            'bias_types_distribution': bias_types_count\n",
        "        }\n",
        "\n",
        "# Bias-Analyzer Instanz\n",
        "bias_analyzer = BiasAnalyzer()\n",
        "\n",
        "def create_enhanced_analysis_interface():\n",
        "    \"\"\"Erweiterte Analyse mit automatischer Bias-Erkennung\"\"\"\n",
        "    \n",
        "    analysis_output = widgets.Output()\n",
        "    \n",
        "    def analyze_last_result():\n",
        "        \"\"\"Analysiert das letzte Test-Ergebnis\"\"\"\n",
        "        \n",
        "        if not bias_lab.test_results:\n",
        "            return \"Noch keine Tests zum Analysieren vorhanden.\"\n",
        "        \n",
        "        last_result = bias_lab.test_results[-1]\n",
        "        \n",
        "        # Bias-Analyse durchf√ºhren\n",
        "        term_info = {\n",
        "            'word': last_result['term'],\n",
        "            'bias_category': last_result['category']\n",
        "        }\n",
        "        \n",
        "        analysis = bias_analyzer.analyze_response(last_result['response'], term_info)\n",
        "        \n",
        "        # Reflexionsfragen generieren\n",
        "        questions = bias_analyzer.generate_reflection_questions(analysis)\n",
        "        \n",
        "        return analysis, questions\n",
        "    \n",
        "    def show_comprehensive_analysis():\n",
        "        \"\"\"Zeigt umfassende Bias-Analyse\"\"\"\n",
        "        \n",
        "        with analysis_output:\n",
        "            clear_output(wait=True)\n",
        "            \n",
        "            if not bias_lab.test_results:\n",
        "                print(\"üì≠ Noch keine Tests durchgef√ºhrt.\")\n",
        "                return\n",
        "            \n",
        "            print(\"üîç BIAS-ANALYSE DER LETZTEN ANTWORT\")\n",
        "            print(\"=\" * 50)\n",
        "            \n",
        "            analysis, questions = analyze_last_result()\n",
        "            \n",
        "            print(f\"üìö Begriff: {analysis['term']}\")\n",
        "            print(f\"üè∑Ô∏è Kategorie: {analysis['category']}\")\n",
        "            print(f\"üìè Antwortl√§nge: {analysis['response_length']} Zeichen\")\n",
        "            print(f\"‚ö†Ô∏è Bias-Score: {analysis['bias_score']}/5\")\n",
        "            \n",
        "            if analysis['detected_bias']:\n",
        "                print(f\"\\nüö® Erkannte Bias-Muster:\")\n",
        "                for bias_type, indicators in analysis['detected_bias'].items():\n",
        "                    bias_name = bias_type.replace('_', ' ').title()\n",
        "                    print(f\"   ‚Ä¢ {bias_name}: {', '.join(indicators)}\")\n",
        "            else:\n",
        "                print(f\"\\n‚úÖ Keine automatisch erkennbaren Bias-Muster gefunden\")\n",
        "            \n",
        "            print(f\"\\nüí≠ REFLEXIONSFRAGEN:\")\n",
        "            for i, question in enumerate(questions, 1):\n",
        "                print(f\"   {i}. {question}\")\n",
        "            \n",
        "            # Workshop-Diskussion\n",
        "            print(f\"\\nüó£Ô∏è DISKUSSIONSPUNKTE:\")\n",
        "            print(f\"   ‚Ä¢ Wie beeinflusst die Prompt-Formulierung diese Antwort?\")\n",
        "            print(f\"   ‚Ä¢ Welche historischen Quellen w√ºrden Sie zur Validierung heranziehen?\")\n",
        "            print(f\"   ‚Ä¢ Wie k√∂nnte der Prompt verbessert werden?\")\n",
        "            \n",
        "            # Gesamtstatistik\n",
        "            stats = bias_analyzer.get_summary_stats()\n",
        "            if stats and stats['total_analyses'] > 1:\n",
        "                print(f\"\\nüìä WORKSHOP-STATISTIK:\")\n",
        "                print(f\"   ‚Ä¢ Analysierte Antworten: {stats['total_analyses']}\")\n",
        "                print(f\"   ‚Ä¢ Bias-Rate: {stats['bias_rate']:.1f}%\")\n",
        "                if stats['most_common_bias']:\n",
        "                    most_common = stats['most_common_bias'][0].replace('_', ' ').title()\n",
        "                    print(f\"   ‚Ä¢ H√§ufigster Bias-Typ: {most_common}\")\n",
        "    \n",
        "    analyze_button = widgets.Button(\n",
        "        description='üîç Letzte Antwort analysieren',\n",
        "        button_style='warning',\n",
        "        icon='search'\n",
        "    )\n",
        "    \n",
        "    analyze_button.on_click(lambda x: show_comprehensive_analysis())\n",
        "    \n",
        "    return widgets.VBox([\n",
        "        widgets.HTML(\"<h3>üîç Automatische Bias-Analyse</h3>\"),\n",
        "        widgets.HTML(\"<p>Erkennt automatisch problematische Muster in LLM-Antworten</p>\"),\n",
        "        analyze_button,\n",
        "        analysis_output\n",
        "    ])\n",
        "\n",
        "# Enhanced Analysis Interface anzeigen\n",
        "enhanced_analysis = create_enhanced_analysis_interface()\n",
        "display(enhanced_analysis)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üî¨ Prompt-Vergleichs-Labor\n",
        "\n",
        "def create_prompt_comparison_lab():\n",
        "    \"\"\"Erm√∂glicht systematischen Vergleich verschiedener Prompt-Strategien\"\"\"\n",
        "    \n",
        "    comparison_data = []\n",
        "    \n",
        "    # Vordefinierte Prompt-Strategien f√ºr Vergleiche\n",
        "    prompt_strategies = {\n",
        "        'neutral_historisch': {\n",
        "            'name': 'üèõÔ∏è Neutral-historisch',\n",
        "            'template': 'Erkl√§re die Bedeutung des mittelhochdeutschen Begriffs \"{word}\" im historischen Kontext des 12.-13. Jahrhunderts.',\n",
        "            'description': 'Fokus auf historische Einordnung ohne moderne Bewertung'\n",
        "        },\n",
        "        'kritisch_analytisch': {\n",
        "            'name': 'üîç Kritisch-analytisch', \n",
        "            'template': 'Analysiere den Begriff \"{word}\" aus der mittelalterlichen Literatur. Welche gesellschaftlichen Strukturen und Wertvorstellungen spiegelt er wider?',\n",
        "            'description': 'Hinterfragt gesellschaftliche Implikationen'\n",
        "        },\n",
        "        'bias_sensitiv': {\n",
        "            'name': '‚öñÔ∏è Bias-sensitiv',\n",
        "            'template': 'Erkl√§re den mittelalterlichen Begriff \"{word}\" und reflektiere dabei m√∂gliche Vorurteile oder Stereotypen, die er transportieren k√∂nnte.',\n",
        "            'description': 'Explizite Sensibilisierung f√ºr Bias-Aspekte'\n",
        "        },\n",
        "        'modern_transfer': {\n",
        "            'name': 'üîÑ Modern-Transfer',\n",
        "            'template': 'Vergleiche die mittelalterliche Verwendung von \"{word}\" mit modernen Begriffen. Was hat sich in der Bedeutung ver√§ndert?',\n",
        "            'description': 'Bewusste Verbindung zwischen historisch und modern'\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    # Interface-Elemente\n",
        "    term_selector = widgets.Dropdown(\n",
        "        options=[],\n",
        "        description='Begriff:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "    \n",
        "    strategy_selector = widgets.Dropdown(\n",
        "        options=[(info['name'], key) for key, info in prompt_strategies.items()],\n",
        "        description='Strategie:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "    \n",
        "    strategy_info = widgets.HTML()\n",
        "    current_prompt = widgets.Textarea(\n",
        "        layout=widgets.Layout(width='100%', height='80px'),\n",
        "        description='Prompt:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "    \n",
        "    test_button = widgets.Button(\n",
        "        description='üß™ Test durchf√ºhren',\n",
        "        button_style='primary'\n",
        "    )\n",
        "    \n",
        "    comparison_output = widgets.Output()\n",
        "    \n",
        "    # Populate term selector\n",
        "    all_terms = [(f\"{row['word']} ({row['bias_category']})\", idx) \n",
        "                 for idx, row in df.iterrows()]\n",
        "    term_selector.options = all_terms\n",
        "    \n",
        "    def update_strategy_info(change):\n",
        "        \"\"\"Aktualisiert Strategie-Info und Prompt\"\"\"\n",
        "        strategy_key = change['new']\n",
        "        strategy = prompt_strategies[strategy_key]\n",
        "        \n",
        "        strategy_info.value = f\"<p><strong>{strategy['name']}</strong>: {strategy['description']}</p>\"\n",
        "        \n",
        "        # Update prompt with current term\n",
        "        if term_selector.value is not None:\n",
        "            term_data = df.iloc[term_selector.value]\n",
        "            current_prompt.value = strategy['template'].format(word=term_data['word'])\n",
        "    \n",
        "    def update_prompt_for_term(change):\n",
        "        \\\"\\\"\\\"Aktualisiert Prompt bei Term-Wechsel\\\"\\\"\\\"\n",
        "        if change['new'] is not None:\n",
        "            term_data = df.iloc[change['new']]\n",
        "            strategy_key = strategy_selector.value\n",
        "            strategy = prompt_strategies[strategy_key]\n",
        "            current_prompt.value = strategy['template'].format(word=term_data['word'])\n",
        "    \n",
        "    def run_comparison_test(button):\n",
        "        \\\"\\\"\\\"F√ºhrt Test durch und speichert f√ºr Vergleich\\\"\\\"\\\"\n",
        "        \n",
        "        with comparison_output:\n",
        "            if not bias_lab.api_available:\n",
        "                print(\"‚ùå API nicht verf√ºgbar! Bitte testen Sie die API zuerst.\")\n",
        "                return\n",
        "            \n",
        "            if term_selector.value is None:\n",
        "                print(\"‚ùå Bitte w√§hlen Sie einen Begriff aus.\")\n",
        "                return\n",
        "            \n",
        "            term_data = df.iloc[term_selector.value]\n",
        "            strategy_key = strategy_selector.value\n",
        "            strategy = prompt_strategies[strategy_key]\n",
        "            prompt = current_prompt.value\n",
        "            \n",
        "            print(f\"üß™ Test l√§uft...\")\n",
        "            print(f\"üìö Begriff: {term_data['word']}\")\n",
        "            print(f\"üéØ Strategie: {strategy['name']}\")\n",
        "            print(f\"ü§ñ Modell: {bias_lab.MODELS[bias_lab.selected_model]}\")\n",
        "            print(\"-\" * 40)\n",
        "            \n",
        "            # LLM-Anfrage\n",
        "            response = bias_lab.send_prompt(prompt)\n",
        "            \n",
        "            # Bias-Analyse\n",
        "            analysis = bias_analyzer.analyze_response(response, {\n",
        "                'word': term_data['word'],\n",
        "                'bias_category': term_data['bias_category']\n",
        "            })\n",
        "            \n",
        "            # Ergebnis speichern\n",
        "            comparison_result = {\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'term': term_data['word'],\n",
        "                'category': term_data['bias_category'],\n",
        "                'strategy': strategy_key,\n",
        "                'strategy_name': strategy['name'],\n",
        "                'prompt': prompt,\n",
        "                'response': response,\n",
        "                'bias_analysis': analysis,\n",
        "                'model': bias_lab.selected_model\n",
        "            }\n",
        "            \n",
        "            comparison_data.append(comparison_result)\n",
        "            \n",
        "            print(f\"üìù Antwort: {response[:200]}...\")\n",
        "            print(f\"\\\\n‚ö†Ô∏è Bias-Score: {analysis['bias_score']}/5\")\n",
        "            \n",
        "            if analysis['detected_bias']:\n",
        "                print(f\"üö® Erkannte Bias-Muster:\")\n",
        "                for bias_type, indicators in analysis['detected_bias'].items():\n",
        "                    print(f\"   ‚Ä¢ {bias_type}: {', '.join(indicators[:2])}\")\n",
        "            \n",
        "            print(f\"\\\\n‚úÖ Test #{len(comparison_data)} gespeichert f√ºr Vergleich\")\n",
        "    \n",
        "    def show_comparison_results():\n",
        "        \\\"\\\"\\\"Zeigt Vergleichs√ºbersicht\\\"\\\"\\\"\n",
        "        \n",
        "        with comparison_output:\n",
        "            clear_output(wait=True)\n",
        "            \n",
        "            if len(comparison_data) < 2:\n",
        "                print(\"üìä Mindestens 2 Tests erforderlich f√ºr Vergleich\")\n",
        "                print(f\"Aktuelle Tests: {len(comparison_data)}\")\n",
        "                return\n",
        "            \n",
        "            print(\"üìä PROMPT-STRATEGIEN VERGLEICH\")\n",
        "            print(\"=\" * 50)\n",
        "            \n",
        "            # Gruppierung nach Begriff\n",
        "            by_term = {}\n",
        "            for result in comparison_data:\n",
        "                term = result['term']\n",
        "                if term not in by_term:\n",
        "                    by_term[term] = []\n",
        "                by_term[term].append(result)\n",
        "            \n",
        "            for term, results in by_term.items():\n",
        "                if len(results) > 1:\n",
        "                    print(f\"\\\\nüìö Begriff: {term}\")\n",
        "                    print(\"-\" * 30)\n",
        "                    \n",
        "                    for result in results:\n",
        "                        bias_score = result['bias_analysis']['bias_score']\n",
        "                        print(f\"   {result['strategy_name']}: Bias-Score {bias_score}/5\")\n",
        "                        \n",
        "                        if result['bias_analysis']['detected_bias']:\n",
        "                            bias_types = list(result['bias_analysis']['detected_bias'].keys())\n",
        "                            print(f\"     ‚Üí Bias-Typen: {', '.join(bias_types)}\")\n",
        "                        else:\n",
        "                            print(f\"     ‚Üí Keine erkennbaren Bias-Muster\")\n",
        "            \n",
        "            # Strategien-Ranking\n",
        "            strategy_scores = {}\n",
        "            for result in comparison_data:\n",
        "                strategy = result['strategy_name']\n",
        "                score = result['bias_analysis']['bias_score']\n",
        "                \n",
        "                if strategy not in strategy_scores:\n",
        "                    strategy_scores[strategy] = []\n",
        "                strategy_scores[strategy].append(score)\n",
        "            \n",
        "            print(f\"\\\\nüèÜ STRATEGIEN-RANKING (niedrigster Bias-Score = besser):\")\n",
        "            print(\"-\" * 50)\n",
        "            \n",
        "            for strategy, scores in strategy_scores.items():\n",
        "                avg_score = sum(scores) / len(scores)\n",
        "                print(f\"   {strategy}: ‚åÄ {avg_score:.1f} Bias-Score ({len(scores)} Tests)\")\n",
        "            \n",
        "            print(f\"\\\\nüí° WORKSHOP-ERKENNTNISSE:\")\n",
        "            print(f\"   ‚Ä¢ Welche Prompt-Strategie erzeugt neutralere Antworten?\")\n",
        "            print(f\"   ‚Ä¢ Gibt es terme-spezifische Unterschiede?\")\n",
        "            print(f\"   ‚Ä¢ Wie beeinflusst die Fragestellung die Bias-Neigung?\")\n",
        "    \n",
        "    compare_button = widgets.Button(\n",
        "        description='üìä Ergebnisse vergleichen',\n",
        "        button_style='info'\n",
        "    )\n",
        "    \n",
        "    compare_button.on_click(lambda x: show_comparison_results())\n",
        "    \n",
        "    # Event-Bindings\n",
        "    strategy_selector.observe(update_strategy_info, names='value')\n",
        "    term_selector.observe(update_prompt_for_term, names='value')\n",
        "    test_button.on_click(run_comparison_test)\n",
        "    \n",
        "    # Initial setup\n",
        "    if strategy_selector.options:\n",
        "        strategy_selector.value = strategy_selector.options[0][1]\n",
        "    if term_selector.options:\n",
        "        term_selector.value = term_selector.options[0][1]\n",
        "    \n",
        "    return widgets.VBox([\n",
        "        widgets.HTML(\"<h3>üî¨ Prompt-Strategien-Labor</h3>\"),\n",
        "        widgets.HTML(\"<p>Systematischer Vergleich verschiedener Prompt-Ans√§tze</p>\"),\n",
        "        widgets.HBox([term_selector, strategy_selector]),\n",
        "        strategy_info,\n",
        "        current_prompt,\n",
        "        widgets.HBox([test_button, compare_button]),\n",
        "        comparison_output\n",
        "    ])\n",
        "\n",
        "# Comparison Lab anzeigen\n",
        "comparison_lab = create_prompt_comparison_lab()\n",
        "display(comparison_lab)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìù Workshop-Reflexion & Dokumentation\n",
        "\n",
        "def create_workshop_reflection():\n",
        "    \"\"\"Tool f√ºr strukturierte Workshop-Reflexion und Dokumentation\"\"\"\n",
        "    \n",
        "    reflection_notes = []\n",
        "    \n",
        "    # Reflexions-Kategorien\n",
        "    reflection_categories = {\n",
        "        'bias_patterns': {\n",
        "            'title': 'üö® Erkannte Bias-Muster',\n",
        "            'questions': [\n",
        "                'Welche Bias-Typen sind besonders h√§ufig aufgetreten?',\n",
        "                'Gibt es kategorie-spezifische Bias-Muster?',\n",
        "                'Welche modernen Konzepte werden auf mittelalterliche Verh√§ltnisse projiziert?'\n",
        "            ]\n",
        "        },\n",
        "        'prompt_strategies': {\n",
        "            'title': '‚úçÔ∏è Prompt-Strategien',\n",
        "            'questions': [\n",
        "                'Welche Prompt-Formulierungen erzeugen neutralere Antworten?',\n",
        "                'Wie beeinflusst die Fragestellung die LLM-Antworten?',\n",
        "                'Welche Strategien eignen sich am besten f√ºr historische Forschung?'\n",
        "            ]\n",
        "        },\n",
        "        'model_behavior': {\n",
        "            'title': 'ü§ñ Modell-Verhalten',\n",
        "            'questions': [\n",
        "                'Gibt es Unterschiede zwischen den MLVoca-Modellen?',\n",
        "                'Welche St√§rken und Schw√§chen zeigen die Modelle?',\n",
        "                'Wie konsistent sind die Antworten bei wiederholten Anfragen?'\n",
        "            ]\n",
        "        },\n",
        "        'historical_accuracy': {\n",
        "            'title': 'üìö Historische Genauigkeit',\n",
        "            'questions': [\n",
        "                'Werden historische Kontexte korrekt dargestellt?',\n",
        "                'Wo entstehen anachronistische Interpretationen?',\n",
        "                'Wie gut gelingt die Quellenverortung?'\n",
        "            ]\n",
        "        },\n",
        "        'practical_insights': {\n",
        "            'title': 'üí° Praktische Erkenntnisse',\n",
        "            'questions': [\n",
        "                'Wie k√∂nnen Sie diese Erkenntnisse in Ihrer Forschung nutzen?',\n",
        "                'Welche Vorsichtsma√ünahmen sind bei LLM-Nutzung wichtig?',\n",
        "                'Welche weiteren Tools/Methoden w√§ren hilfreich?'\n",
        "            ]\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    # Interface-Elemente\n",
        "    category_selector = widgets.Dropdown(\n",
        "        options=[(info['title'], key) for key, info in reflection_categories.items()],\n",
        "        description='Kategorie:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "    \n",
        "    questions_display = widgets.HTML()\n",
        "    \n",
        "    notes_editor = widgets.Textarea(\n",
        "        placeholder='Ihre Beobachtungen und Erkenntnisse zu dieser Kategorie...',\n",
        "        layout=widgets.Layout(width='100%', height='120px'),\n",
        "        description='Notizen:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "    \n",
        "    save_button = widgets.Button(\n",
        "        description='üíæ Notiz speichern',\n",
        "        button_style='success'\n",
        "    )\n",
        "    \n",
        "    export_button = widgets.Button(\n",
        "        description='üìÑ Reflexion exportieren',\n",
        "        button_style='info'\n",
        "    )\n",
        "    \n",
        "    reflection_output = widgets.Output()\n",
        "    \n",
        "    def update_questions(change):\n",
        "        \"\"\"Aktualisiert Reflexionsfragen f√ºr gew√§hlte Kategorie\"\"\"\n",
        "        category_key = change['new']\n",
        "        category = reflection_categories[category_key]\n",
        "        \n",
        "        questions_html = f\"<h4>{category['title']}</h4>\"\n",
        "        questions_html += \"<ul>\"\n",
        "        for question in category['questions']:\n",
        "            questions_html += f\"<li>{question}</li>\"\n",
        "        questions_html += \"</ul>\"\n",
        "        \n",
        "        questions_display.value = questions_html\n",
        "        \n",
        "        # Lade existierende Notizen f√ºr diese Kategorie\n",
        "        existing_note = next((note for note in reflection_notes if note['category'] == category_key), None)\n",
        "        if existing_note:\n",
        "            notes_editor.value = existing_note['content']\n",
        "        else:\n",
        "            notes_editor.value = \"\"\n",
        "    \n",
        "    def save_reflection_note(button):\n",
        "        \"\"\"Speichert Reflexions-Notiz\"\"\"\n",
        "        category_key = category_selector.value\n",
        "        content = notes_editor.value.strip()\n",
        "        \n",
        "        if not content:\n",
        "            with reflection_output:\n",
        "                clear_output(wait=True)\n",
        "                print(\"‚ùå Bitte geben Sie eine Notiz ein.\")\n",
        "            return\n",
        "        \n",
        "        # Aktualisiere oder f√ºge Notiz hinzu\n",
        "        existing_note = next((note for note in reflection_notes if note['category'] == category_key), None)\n",
        "        \n",
        "        if existing_note:\n",
        "            existing_note['content'] = content\n",
        "            existing_note['timestamp'] = datetime.now().isoformat()\n",
        "        else:\n",
        "            reflection_notes.append({\n",
        "                'category': category_key,\n",
        "                'category_title': reflection_categories[category_key]['title'],\n",
        "                'content': content,\n",
        "                'timestamp': datetime.now().isoformat()\n",
        "            })\n",
        "        \n",
        "        with reflection_output:\n",
        "            clear_output(wait=True)\n",
        "            print(f\"‚úÖ Notiz zu '{reflection_categories[category_key]['title']}' gespeichert\")\n",
        "            print(f\"üìù Gesamt-Notizen: {len(reflection_notes)}\")\n",
        "    \n",
        "    def export_workshop_reflection(button):\n",
        "        \"\"\"Exportiert komplette Workshop-Reflexion\"\"\"\n",
        "        \n",
        "        with reflection_output:\n",
        "            clear_output(wait=True)\n",
        "            \n",
        "            if not reflection_notes:\n",
        "                print(\"‚ùå Keine Reflexions-Notizen zum Exportieren vorhanden.\")\n",
        "                return\n",
        "            \n",
        "            # Statistiken sammeln\n",
        "            total_tests = len(bias_lab.test_results)\n",
        "            total_analyses = len(bias_analyzer.analyses)\n",
        "            \n",
        "            # Export-Daten zusammenstellen\n",
        "            export_data = {\n",
        "                'workshop_metadata': {\n",
        "                    'title': 'MHDBDB Bias Detection Workshop - MLVoca.com',\n",
        "                    'date': datetime.now().isoformat(),\n",
        "                    'api_provider': 'MLVoca.com (Free LLM API)',\n",
        "                    'total_tests': total_tests,\n",
        "                    'total_analyses': total_analyses\n",
        "                },\n",
        "                'reflection_notes': reflection_notes,\n",
        "                'workshop_statistics': {\n",
        "                    'tests_conducted': total_tests,\n",
        "                    'bias_analyses': total_analyses,\n",
        "                    'bias_rate': bias_analyzer.get_summary_stats()['bias_rate'] if bias_analyzer.get_summary_stats() else 0\n",
        "                },\n",
        "                'test_results': bias_lab.test_results,\n",
        "                'bias_analyses': bias_analyzer.analyses\n",
        "            }\n",
        "            \n",
        "            # Datei speichern\n",
        "            filename = f\"mhdbdb_workshop_reflection_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "            \n",
        "            with open(filename, 'w', encoding='utf-8') as f:\n",
        "                json.dump(export_data, f, indent=2, ensure_ascii=False)\n",
        "            \n",
        "            print(f\"‚úÖ Workshop-Reflexion exportiert: {filename}\")\n",
        "            print(f\"üìä Enth√§lt:\")\n",
        "            print(f\"   ‚Ä¢ {len(reflection_notes)} Reflexions-Notizen\")\n",
        "            print(f\"   ‚Ä¢ {total_tests} Test-Ergebnisse\")\n",
        "            print(f\"   ‚Ä¢ {total_analyses} Bias-Analysen\")\n",
        "            \n",
        "            # Kurze Zusammenfassung anzeigen\n",
        "            print(f\"\\\\nüìã WORKSHOP-ZUSAMMENFASSUNG:\")\n",
        "            print(f\"=\" * 40)\n",
        "            \n",
        "            for note in reflection_notes:\n",
        "                print(f\"\\\\n{note['category_title']}:\")\n",
        "                preview = note['content'][:100] + \"...\" if len(note['content']) > 100 else note['content']\n",
        "                print(f\"   {preview}\")\n",
        "    \n",
        "    # Event-Bindings\n",
        "    category_selector.observe(update_questions, names='value')\n",
        "    save_button.on_click(save_reflection_note)\n",
        "    export_button.on_click(export_workshop_reflection)\n",
        "    \n",
        "    # Initial setup\n",
        "    if category_selector.options:\n",
        "        category_selector.value = category_selector.options[0][1]\n",
        "    \n",
        "    return widgets.VBox([\n",
        "        widgets.HTML(\"<h3>üìù Workshop-Reflexion</h3>\"),\n",
        "        widgets.HTML(\"<p>Strukturierte Dokumentation Ihrer Workshop-Erkenntnisse</p>\"),\n",
        "        category_selector,\n",
        "        questions_display,\n",
        "        notes_editor,\n",
        "        widgets.HBox([save_button, export_button]),\n",
        "        reflection_output\n",
        "    ])\n",
        "\n",
        "# Workshop-Reflexion anzeigen\n",
        "workshop_reflection = create_workshop_reflection()\n",
        "display(workshop_reflection)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üéØ Workshop-Zusammenfassung & N√§chste Schritte\n",
        "\n",
        "print(\"üéì MHDBDB Bias Detection Workshop - Abschluss\")\n",
        "print(\"=\" * 55)\n",
        "print()\n",
        "print(\"üìö Was Sie gelernt haben:\")\n",
        "print(\"   ‚úì Bias-Erkennung in LLM-Antworten zu historischen Begriffen\")\n",
        "print(\"   ‚úì Kritische Analyse mittelalterlicher Terminologie\")\n",
        "print(\"   ‚úì Prompt-Engineering f√ºr historische Forschung\")\n",
        "print(\"   ‚úì Systematischen Vergleich verschiedener Ans√§tze\")\n",
        "print(\"   ‚úì Strukturierte Reflexion von KI-Ergebnissen\")\n",
        "print()\n",
        "print(\"üîß Verwendete Tools:\")\n",
        "print(\"   ‚Ä¢ MLVoca.com - Kostenlose LLM API (TinyLlama, DeepSeek)\")\n",
        "print(\"   ‚Ä¢ Automatische Bias-Erkennung mit 5 Kategorien\")\n",
        "print(\"   ‚Ä¢ Prompt-Strategien-Vergleich\")\n",
        "print(\"   ‚Ä¢ Strukturierte Workshop-Reflexion\")\n",
        "print()\n",
        "print(\"üí° Wichtige Erkenntnisse:\")\n",
        "print(\"   ‚Ä¢ LLMs neigen zu Anachronismen bei historischen Begriffen\")\n",
        "print(\"   ‚Ä¢ Prompt-Formulierung beeinflusst Bias-Neigung erheblich\")\n",
        "print(\"   ‚Ä¢ Kritische Quellenvalidierung bleibt unerl√§sslich\")\n",
        "print(\"   ‚Ä¢ Verschiedene Modelle zeigen unterschiedliche Bias-Muster\")\n",
        "print()\n",
        "print(\"üöÄ N√§chste Schritte:\")\n",
        "print(\"   1. Exportieren Sie Ihre Workshop-Ergebnisse\")\n",
        "print(\"   2. Testen Sie weitere MHDBDB-Begriffe\")\n",
        "print(\"   3. Entwickeln Sie eigene Prompt-Strategien\")\n",
        "print(\"   4. Integrieren Sie Bias-Checks in Ihre Forschung\")\n",
        "print()\n",
        "print(\"üìñ Weiterf√ºhrende Ressourcen:\")\n",
        "print(\"   ‚Ä¢ MHDBDB TEI Repository: github.com/DigitalHumanitiesCraft/mhdbdb-tei-only\")\n",
        "print(\"   ‚Ä¢ MLVoca.com Documentation: mlvoca.github.io/free-llm-api/\")\n",
        "print(\"   ‚Ä¢ Workshop-Beispielsammlung: siehe Workshop_Beispielsammlung.md\")\n",
        "print()\n",
        "print(\"üôè Vielen Dank f√ºr Ihre Teilnahme!\")\n",
        "print(\"   Feedback und Fragen gerne an das MHDBDB-Team\")\n",
        "print(\"=\" * 55)\n",
        "\n",
        "# Finaler Status-Check\n",
        "def final_workshop_status():\n",
        "    \"\"\"Zeigt abschlie√üenden Workshop-Status\"\"\"\n",
        "    \n",
        "    print(\"\\\\nüìä IHR WORKSHOP-STATUS:\")\n",
        "    print(\"-\" * 30)\n",
        "    \n",
        "    # API-Status\n",
        "    api_status = \"‚úÖ Verf√ºgbar\" if bias_lab.api_available else \"‚ùå Nicht verf√ºgbar\"\n",
        "    print(f\"MLVoca API: {api_status}\")\n",
        "    \n",
        "    # Tests durchgef√ºhrt\n",
        "    test_count = len(bias_lab.test_results)\n",
        "    print(f\"Durchgef√ºhrte Tests: {test_count}\")\n",
        "    \n",
        "    # Bias-Analysen\n",
        "    analysis_count = len(bias_analyzer.analyses)\n",
        "    print(f\"Bias-Analysen: {analysis_count}\")\n",
        "    \n",
        "    # Bias-Rate\n",
        "    if bias_analyzer.get_summary_stats():\n",
        "        bias_rate = bias_analyzer.get_summary_stats()['bias_rate']\n",
        "        print(f\"Durchschnittliche Bias-Rate: {bias_rate:.1f}%\")\n",
        "    \n",
        "    # Empfehlungen\n",
        "    print(\"\\\\nüí° EMPFEHLUNGEN:\")\n",
        "    if test_count == 0:\n",
        "        print(\"   ‚Üí F√ºhren Sie einige Tests mit dem Prompt-Tool durch\")\n",
        "    elif test_count < 5:\n",
        "        print(\"   ‚Üí Testen Sie weitere Begriffe f√ºr umfassendere Erkenntnisse\")\n",
        "    else:\n",
        "        print(\"   ‚Üí Excellent! Nutzen Sie das Vergleichs-Tool f√ºr tiefere Analyse\")\n",
        "    \n",
        "    if analysis_count == 0:\n",
        "        print(\"   ‚Üí Verwenden Sie das Bias-Analyse-Tool\")\n",
        "    \n",
        "    print(\"   ‚Üí Dokumentieren Sie Ihre Erkenntnisse im Reflexions-Tool\")\n",
        "    print(\"   ‚Üí Exportieren Sie Ihre Ergebnisse f√ºr weitere Verwendung\")\n",
        "\n",
        "final_workshop_status()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
