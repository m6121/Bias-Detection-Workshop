{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MHDBDB Bias Detection Workshop\n",
    "\n",
    "**Workshop f√ºr kritische KI-Kompetenz in den Digital Humanities**\n",
    "\n",
    "---\n",
    "\n",
    "## Workshop-√úberblick\n",
    "\n",
    "**API:** MLVoca.com (kostenlos, ausschlie√ülich akademische Nutzung)  \n",
    "**Fokus:** Bias-Erkennung bei historischen Textdaten\n",
    "\n",
    "### Lernziele:\n",
    "1. **Bias-Erkennung** in LLM-Antworten zu historischen Begriffen\n",
    "2. **Kritische Quellenanalyse** von KI-generierten Inhalten\n",
    "3. **Prompt-Engineering** f√ºr historische Forschung\n",
    "4. **Reflektierte KI-Nutzung** in den Digital Humanities\n",
    "\n",
    "### Workshop-Ablauf:\n",
    "- **Phase 1:** Set Up, Bias-Detektiv*innen\n",
    "- **Phase 2:** Prompt-Engineering: Selbstst√§ndig und anhand von Testfragen\n",
    "- **Phase 3:** Reflexion & Diskussion\n",
    "\n",
    "---\n",
    "\n",
    "**Starten Sie mit der n√§chsten Code-Zelle!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MHDBDB Bias Detection Workshop\n",
      "========================================\n",
      "Pakete geladen\n",
      "Workshop-Konfiguration initialisiert\n",
      "Bereit f√ºr Bias-Detection!\n"
     ]
    }
   ],
   "source": [
    "# Setup - MLVoca.com Workshop\n",
    "print(\"MHDBDB Bias Detection Workshop\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Workshop-Konfiguration\n",
    "class WorkshopConfig:\n",
    "    \"\"\"Zentrale Konfiguration f√ºr Workshop-Parameter\"\"\"\n",
    "    API_BASE_URL = \"https://mlvoca.com/api/generate\"\n",
    "    API_TIMEOUT = 30\n",
    "    API_RETRY_ATTEMPTS = 3\n",
    "    API_RETRY_DELAY = 2  # Sekunden\n",
    "    MAX_RESPONSE_LENGTH = 5000\n",
    "    \n",
    "    MODELS = {\n",
    "        \"tinyllama\": \"TinyLlama (Schnell & Kompakt)\",\n",
    "        \"deepseek-r1:1.5b\": \"DeepSeek R1 1.5B (Reasoning)\"\n",
    "    }\n",
    "\n",
    "print(\"Pakete geladen\")\n",
    "print(\"Workshop-Konfiguration initialisiert\")\n",
    "print(\"Bereit f√ºr Bias-Detection!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teste MLVoca.com API...\n",
      " Verbindung wird aufgebaut...\n",
      "‚úì MLVoca.com API verf√ºgbar!\n",
      "\n",
      " Bereit f√ºr Workshop!\n",
      "Kein API-Key erforderlich - v√∂llig kostenlos!\n",
      "Verf√ºgbare Modelle: tinyllama, deepseek-r1:1.5b\n"
     ]
    }
   ],
   "source": [
    "# MLVoca.com API-Setup\n",
    "\n",
    "class MLVoca_BiasLab:\n",
    "    \"\"\"Robustes MLVoca.com Interface f√ºr Workshop\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.selected_model = \"tinyllama\"\n",
    "        self.api_available = False\n",
    "        self.results = []\n",
    "        self.config = WorkshopConfig()\n",
    "        \n",
    "    def _make_api_request(self, payload, timeout=None):\n",
    "        \"\"\"Macht API-Request mit Retry-Logik\"\"\"\n",
    "        timeout = timeout or self.config.API_TIMEOUT\n",
    "        \n",
    "        for attempt in range(self.config.API_RETRY_ATTEMPTS):\n",
    "            try:\n",
    "                response = requests.post(\n",
    "                    self.config.API_BASE_URL,\n",
    "                    json=payload,\n",
    "                    timeout=timeout\n",
    "                )\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    return True, response\n",
    "                elif response.status_code == 429:  # Rate limit\n",
    "                    if attempt < self.config.API_RETRY_ATTEMPTS - 1:\n",
    "                        time.sleep(self.config.API_RETRY_DELAY * (attempt + 1))\n",
    "                        continue\n",
    "                    return False, f\"API-Rate-Limit erreicht nach {attempt + 1} Versuchen\"\n",
    "                else:\n",
    "                    return False, f\"API-Fehler: {response.status_code} - {response.text[:100]}\"\n",
    "                    \n",
    "            except requests.exceptions.Timeout:\n",
    "                if attempt < self.config.API_RETRY_ATTEMPTS - 1:\n",
    "                    time.sleep(self.config.API_RETRY_DELAY)\n",
    "                    continue\n",
    "                return False, f\"Timeout nach {timeout}s (Versuch {attempt + 1})\"\n",
    "                \n",
    "            except requests.exceptions.ConnectionError:\n",
    "                if attempt < self.config.API_RETRY_ATTEMPTS - 1:\n",
    "                    time.sleep(self.config.API_RETRY_DELAY)\n",
    "                    continue\n",
    "                return False, f\"Verbindungsfehler (Versuch {attempt + 1})\"\n",
    "                \n",
    "            except Exception as e:\n",
    "                return False, f\"Unerwarteter Fehler: {str(e)}\"\n",
    "        \n",
    "        return False, \"Maximale Anzahl von Versuchen erreicht\"\n",
    "    \n",
    "    def test_api(self):\n",
    "        \"\"\"Testet MLVoca API mit robuster Fehlerbehandlung\"\"\"\n",
    "        payload = {\n",
    "            \"model\": \"tinyllama\",\n",
    "            \"prompt\": \"Test\",\n",
    "            \"stream\": False\n",
    "        }\n",
    "        \n",
    "        success, result = self._make_api_request(payload, timeout=10)\n",
    "        \n",
    "        if success:\n",
    "            self.api_available = True\n",
    "            return True, \"MLVoca.com API verf√ºgbar!\"\n",
    "        else:\n",
    "            self.api_available = False\n",
    "            return False, result\n",
    "    \n",
    "    def _validate_input(self, prompt):\n",
    "        \"\"\"Validiert Eingabe-Parameter\"\"\"\n",
    "        if not prompt or not prompt.strip():\n",
    "            return False, \"Prompt darf nicht leer sein\"\n",
    "        \n",
    "        if len(prompt) > 2000:  # Reasonable limit\n",
    "            return False, \"Prompt zu lang (max. 2000 Zeichen)\"\n",
    "        \n",
    "        if not self.selected_model in self.config.MODELS:\n",
    "            return False, f\"Ung√ºltiges Modell: {self.selected_model}\"\n",
    "        \n",
    "        return True, None\n",
    "    \n",
    "    def send_prompt(self, prompt):\n",
    "        \"\"\"Sendet Prompt an MLVoca mit robuster Validierung\"\"\"\n",
    "        if not self.api_available:\n",
    "            return \"API nicht verf√ºgbar. Bitte testen Sie die API zuerst.\"\n",
    "        \n",
    "        # Input-Validierung\n",
    "        valid, error = self._validate_input(prompt)\n",
    "        if not valid:\n",
    "            return f\"Eingabefehler: {error}\"\n",
    "        \n",
    "        # Sicherstellen, dass Antworten auf Deutsch sind\n",
    "        german_prompt = f\"Antworte bitte auf Deutsch. {prompt.strip()}\"\n",
    "        \n",
    "        payload = {\n",
    "            \"model\": self.selected_model,\n",
    "            \"prompt\": german_prompt,\n",
    "            \"stream\": False\n",
    "        }\n",
    "        \n",
    "        success, result = self._make_api_request(payload)\n",
    "        \n",
    "        if success:\n",
    "            response_data = result.json()\n",
    "            response_text = response_data.get('response', 'Keine Antwort erhalten')\n",
    "            \n",
    "            # Antwort-L√§nge begrenzen f√ºr bessere UX\n",
    "            if len(response_text) > self.config.MAX_RESPONSE_LENGTH:\n",
    "                response_text = response_text[:self.config.MAX_RESPONSE_LENGTH] + \"...\\n[Antwort gek√ºrzt]\"\n",
    "            \n",
    "            return response_text\n",
    "        else:\n",
    "            return f\"Fehler: {result}\"\n",
    "\n",
    "# Lab-Instanz erstellen\n",
    "bias_lab = MLVoca_BiasLab()\n",
    "\n",
    "# API-Test mit Loading-Feedback\n",
    "print(\"Teste MLVoca.com API...\")\n",
    "print(\" Verbindung wird aufgebaut...\")\n",
    "\n",
    "success, message = bias_lab.test_api()\n",
    "print(f\"‚úì {message}\" if success else f\"‚úó {message}\")\n",
    "\n",
    "if success:\n",
    "    print(\"\\n Bereit f√ºr Workshop!\")\n",
    "    print(\"Kein API-Key erforderlich - v√∂llig kostenlos!\")\n",
    "    print(f\"Verf√ºgbare Modelle: {', '.join(bias_lab.config.MODELS.keys())}\")\n",
    "else:\n",
    "    print(\"\\n API-Problem - versuchen Sie es sp√§ter erneut\")\n",
    "    print(\"Tipp: Pr√ºfen Sie Ihre Internetverbindung\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lade MHDBDB-Begriffspakete...\n",
      "‚úÖ MHDBDB-Daten aus JSON-Datei geladen\n",
      "‚úÖ 24 MHDBDB-Begriffe geladen\n",
      "üìÇ 4 Bias-Kategorien verf√ºgbar\n",
      "üìö 15 verschiedene Quellentexte\n",
      "\n",
      "üìä Verf√ºgbare Bias-Kategorien:\n",
      "   ‚Ä¢ Behinderung Fremdheit: 7 Begriffe\n",
      "   ‚Ä¢ Ethnisch Religi√∂s: 6 Begriffe\n",
      "   ‚Ä¢ Geschlecht Stand: 6 Begriffe\n",
      "   ‚Ä¢ Sozialer Stand: 5 Begriffe\n",
      "\n",
      "üéØ MHDBDB-Begriffspakete bereit f√ºr freie Prompt-Erstellung!\n"
     ]
    }
   ],
   "source": [
    "# MHDBDB-Daten laden und Wortpaket-Integration\n",
    "\n",
    "def load_mhdbdb_data():\n",
    "    \"\"\"L√§dt kuratierte MHDBDB Bias-Daten aus JSON-Datei oder als Fallback hardcoded\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Versuche JSON-Datei zu laden\n",
    "        with open('mhdbdb_workshop_data.json', 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "        # Konvertiere zu DataFrame\n",
    "        entries = data['workshop_entries']\n",
    "        for entry in entries:\n",
    "            # Standardisiere Feldnamen\n",
    "            entry['source'] = entry.get('source_text', entry.get('source', ''))\n",
    "            entry['author'] = entry.get('source_author', entry.get('author', ''))\n",
    "            \n",
    "        df = pd.DataFrame(entries)\n",
    "        print(\"‚úÖ MHDBDB-Daten aus JSON-Datei geladen\")\n",
    "        return df\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ö†Ô∏è JSON-Datei nicht gefunden - verwende Fallback-Daten\")\n",
    "        # Fallback: Hardcoded Daten\n",
    "        bias_terms = {\n",
    "            \"ethnisch_religi√∂s\": [\n",
    "                {\"word\": \"saraz√Æn\", \"meaning\": \"Angeh√∂riger eines islamischen Volkes; Heide\", \"source\": \"Parzival\", \"author\": \"Wolfram von Eschenbach\"},\n",
    "                {\"word\": \"heiden\", \"meaning\": \"Nicht-Christ; Anh√§nger einer anderen Religion\", \"source\": \"Rolandslied\", \"author\": \"Pfaffe Konrad\"},\n",
    "                {\"word\": \"jude\", \"meaning\": \"Angeh√∂riger der j√ºdischen Religion\", \"source\": \"Marienleben\", \"author\": \"Bruder Philipp\"}\n",
    "            ],\n",
    "            \"geschlecht_stand\": [\n",
    "                {\"word\": \"vrouwe\", \"meaning\": \"Herrin, edle Dame; Ehefrau\", \"source\": \"Iwein\", \"author\": \"Hartmann von Aue\"},\n",
    "                {\"word\": \"w√Æp\", \"meaning\": \"Frau; Ehefrau\", \"source\": \"Nibelungenlied\", \"author\": \"unbekannt\"},\n",
    "                {\"word\": \"maget\", \"meaning\": \"Jungfrau; unverheiratete Frau\", \"source\": \"Kudrun\", \"author\": \"unbekannt\"}\n",
    "            ],\n",
    "            \"sozialer_stand\": [\n",
    "                {\"word\": \"ritter\", \"meaning\": \"Angeh√∂riger des Ritterstandes; Krieger zu Pferde\", \"source\": \"Erec\", \"author\": \"Hartmann von Aue\"},\n",
    "                {\"word\": \"b√ªr\", \"meaning\": \"Bauer, Landmann\", \"source\": \"Meier Helmbrecht\", \"author\": \"Wernher der G√§rtner\"},\n",
    "                {\"word\": \"pfaffe\", \"meaning\": \"Geistlicher, Priester\", \"source\": \"Der arme Heinrich\", \"author\": \"Hartmann von Aue\"}\n",
    "            ],\n",
    "            \"behinderung_fremdheit\": [\n",
    "                {\"word\": \"kr√ºppel\", \"meaning\": \"k√∂rperlich beeintr√§chtigte Person\", \"source\": \"Gregorius\", \"author\": \"Hartmann von Aue\"},\n",
    "                {\"word\": \"blint\", \"meaning\": \"blind; ohne Sehverm√∂gen\", \"source\": \"Gregorius\", \"author\": \"Hartmann von Aue\"},\n",
    "                {\"word\": \"ellende\", \"meaning\": \"Fremde, Verbannung; Elend\", \"source\": \"Kudrun\", \"author\": \"unbekannt\"}\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        # DataFrame erstellen\n",
    "        all_terms = []\n",
    "        for category, terms in bias_terms.items():\n",
    "            for term in terms:\n",
    "                term['bias_category'] = category\n",
    "                all_terms.append(term)\n",
    "\n",
    "        return pd.DataFrame(all_terms)\n",
    "\n",
    "# Daten laden\n",
    "print(\"Lade MHDBDB-Begriffspakete...\")\n",
    "df_mhdbdb = load_mhdbdb_data()\n",
    "\n",
    "# Standardisiere Bias-Kategorien f√ºr konsistente Darstellung\n",
    "if 'bias_category' in df_mhdbdb.columns:\n",
    "    # Vereinheitliche Kategorienamen\n",
    "    category_mapping = {\n",
    "        'ethnisch_religi√∂s': 'ethnisch_religi√∂s',\n",
    "        'geschlecht_stand': 'geschlecht_stand', \n",
    "        'sozialer_stand': 'sozialer_stand',\n",
    "        'behinderung_fremdheit': 'behinderung_fremdheit',\n",
    "        'behinderung': 'behinderung_fremdheit',  # Mapping f√ºr JSON-Daten\n",
    "        'fremdheit': 'behinderung_fremdheit'     # Mapping f√ºr JSON-Daten\n",
    "    }\n",
    "    \n",
    "    df_mhdbdb['bias_category'] = df_mhdbdb['bias_category'].map(category_mapping).fillna(df_mhdbdb['bias_category'])\n",
    "\n",
    "print(f\"‚úÖ {len(df_mhdbdb)} MHDBDB-Begriffe geladen\")\n",
    "print(f\"üìÇ {df_mhdbdb['bias_category'].nunique()} Bias-Kategorien verf√ºgbar\")\n",
    "print(f\"üìö {df_mhdbdb['source'].nunique()} verschiedene Quellentexte\")\n",
    "\n",
    "print(\"\\nüìä Verf√ºgbare Bias-Kategorien:\")\n",
    "for category in sorted(df_mhdbdb['bias_category'].unique()):\n",
    "    count = len(df_mhdbdb[df_mhdbdb['bias_category'] == category])\n",
    "    display_name = category.replace('_', ' ').title()\n",
    "    print(f\"   ‚Ä¢ {display_name}: {count} Begriffe\")\n",
    "\n",
    "print(\"\\nüéØ MHDBDB-Begriffspakete bereit f√ºr freie Prompt-Erstellung!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8db65de9cbba4cd8987afbfdcd5a81ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>‚úçÔ∏è Freie Prompt-Erstellung mit MHDBDB-Begriffspaketen</h3>'), HTML(value='<p><s‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Freie Prompt-Erstellung mit MHDBDB-Begriffspaketen\n",
    "\n",
    "def create_free_prompt_interface():\n",
    "    \"\"\"Interface f√ºr freie Prompt-Erstellung mit MHDBDB-Begriffen\"\"\"\n",
    "\n",
    "    # Begriff-Auswahl nach Kategorien\n",
    "    category_selector = widgets.Dropdown(\n",
    "        options=[(cat.replace('_', ' ').title(), cat) for cat in df_mhdbdb['bias_category'].unique()],\n",
    "        description='Kategorie:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='300px')\n",
    "    )\n",
    "\n",
    "    term_selector = widgets.Dropdown(\n",
    "        options=[],\n",
    "        description='Begriff:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='350px')\n",
    "    )\n",
    "\n",
    "    # Info-Bereich f√ºr gew√§hlten Begriff\n",
    "    term_info = widgets.HTML()\n",
    "\n",
    "\n",
    "\n",
    "    # Gro√üer Prompt-Editor\n",
    "    prompt_editor = widgets.Textarea(\n",
    "        placeholder='Schreiben Sie hier Ihren individuellen Prompt...\\n\\nTipps:\\n- Seien Sie spezifisch\\n- Fragen Sie nach historischem Kontext\\n- Experimentieren Sie mit verschiedenen Ans√§tzen',\n",
    "        description='Ihr Prompt:',\n",
    "        layout=widgets.Layout(width='100%', height='120px'),\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "\n",
    "    # Modell-Auswahl\n",
    "    model_selector = widgets.Dropdown(\n",
    "        options=[(name, key) for key, name in bias_lab.config.MODELS.items()],\n",
    "        value=bias_lab.selected_model,\n",
    "        description='Modell:',\n",
    "        layout=widgets.Layout(width='300px')\n",
    "    )\n",
    "\n",
    "    # Sende-Button\n",
    "    send_button = widgets.Button(\n",
    "        description='üöÄ Prompt senden',\n",
    "        button_style='primary',\n",
    "        icon='paper-plane'\n",
    "    )\n",
    "\n",
    "    # Ergebnis-Bereich\n",
    "    result_output = widgets.Output()\n",
    "\n",
    "    # Event-Handler\n",
    "    def update_terms(change):\n",
    "        \"\"\"Aktualisiert Begriffe basierend auf Kategorie\"\"\"\n",
    "        category = change['new']\n",
    "        filtered_df = df_mhdbdb[df_mhdbdb['bias_category'] == category]\n",
    "\n",
    "        options = [(f\"{row['word']} ({row['source']})\", idx)\n",
    "                  for idx, row in filtered_df.iterrows()]\n",
    "\n",
    "        term_selector.options = options\n",
    "        if options:\n",
    "            term_selector.value = options[0][1]\n",
    "\n",
    "    def update_term_info(change):\n",
    "        \"\"\"Zeigt Info zum gew√§hlten Begriff\"\"\"\n",
    "        if change['new'] is not None:\n",
    "            term_data = df_mhdbdb.iloc[change['new']]\n",
    "\n",
    "            info_html = f\"\"\"\n",
    "            <div style='background: #f0f8ff; padding: 15px; border-radius: 5px; margin: 10px 0; border-left: 4px solid #007bff;'>\n",
    "                <h4 style='margin-top: 0; color: #007bff;'>üìö Begriff: {term_data['word']}</h4>\n",
    "                <p><strong>Bedeutung:</strong> {term_data['meaning']}</p>\n",
    "                <p><strong>Quelle:</strong> {term_data['source']} ({term_data['author']})</p>\n",
    "                <p><strong>Bias-Kategorie:</strong> {term_data['bias_category'].replace('_', ' ').title()}</p>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "\n",
    "            term_info.value = info_html\n",
    "\n",
    "\n",
    "\n",
    "    def send_prompt(button):\n",
    "        \"\"\"Sendet freien Prompt an MLVoca\"\"\"\n",
    "        with result_output:\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            # Eingabe-Validierung\n",
    "            if not bias_lab.api_available:\n",
    "                print(\"‚ùå API nicht verf√ºgbar!\")\n",
    "                print(\"üí° F√ºhren Sie den API-Test in der Setup-Zelle erneut aus\")\n",
    "                return\n",
    "\n",
    "            prompt = prompt_editor.value.strip()\n",
    "            if not prompt:\n",
    "                print(\"‚ùå Bitte geben Sie einen Prompt ein!\")\n",
    "                return\n",
    "\n",
    "            if term_selector.value is None:\n",
    "                print(\"‚ùå Bitte w√§hlen Sie einen Begriff aus!\")\n",
    "                return\n",
    "\n",
    "            # Button deaktivieren\n",
    "            send_button.disabled = True\n",
    "            send_button.description = \"‚è≥ L√§dt...\"\n",
    "\n",
    "            try:\n",
    "                # Modell aktualisieren\n",
    "                bias_lab.selected_model = model_selector.value\n",
    "                \n",
    "                term_data = df_mhdbdb.iloc[term_selector.value]\n",
    "\n",
    "                print(f\"FREIE PROMPT-ERSTELLUNG\")\n",
    "                print(f\"=\" * 50)\n",
    "                print(f\"Begriff: '{term_data['word']}' ({term_data['bias_category'].replace('_', ' ').title()})\")\n",
    "                print(f\"Quelle: {term_data['source']} ({term_data['author']})\")\n",
    "                print(f\"Modell: {bias_lab.config.MODELS[bias_lab.selected_model]}\")\n",
    "                print(f\"\\nIhr Prompt:\")\n",
    "                print(f'\"{prompt}\"')\n",
    "                print(f\"\\n‚è≥ Anfrage wird gesendet... (kann bis zu 30s dauern)\")\n",
    "                print(\"-\" * 50)\n",
    "\n",
    "                # LLM-Anfrage\n",
    "                response = bias_lab.send_prompt(prompt)\n",
    "\n",
    "                # Pr√ºfe auf Fehler-Response\n",
    "                if response.startswith(\"Fehler:\") or response.startswith(\"Eingabefehler:\"):\n",
    "                    print(f\"‚ùå {response}\")\n",
    "                    return\n",
    "\n",
    "                print(f\"‚úÖ ANTWORT ERHALTEN:\")\n",
    "                print(response)\n",
    "\n",
    "                print(f\"\\n\" + \"=\" * 50)\n",
    "                print(f\"üîç REFLEXIONSFRAGEN:\")\n",
    "                print(f\"   ‚Ä¢ Wie wissenschaftlich fundiert ist die Antwort?\")\n",
    "                print(f\"   ‚Ä¢ Werden moderne Begriffe auf das Mittelalter √ºbertragen?\")\n",
    "                print(f\"   ‚Ä¢ Welche Quellen werden genannt oder fehlen?\")\n",
    "                print(f\"   ‚Ä¢ Wie neutral oder bias-behaftet ist die Darstellung?\")\n",
    "                print(f\"   ‚Ä¢ Wie k√∂nnte der Prompt verbessert werden?\")\n",
    "\n",
    "                # Ergebnis speichern\n",
    "                bias_lab.results.append({\n",
    "                    'timestamp': datetime.now().isoformat(),\n",
    "                    'term': term_data['word'],\n",
    "                    'category': term_data['bias_category'],\n",
    "                    'source': term_data['source'],\n",
    "                    'author': term_data['author'],\n",
    "                    'model': bias_lab.selected_model,\n",
    "                    'prompt': prompt,\n",
    "                    'response': response,\n",
    "                    'phase': 'free_prompt_creation'\n",
    "                })\n",
    "\n",
    "                print(f\"\\n‚úÖ Test #{len(bias_lab.results)} gespeichert!\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Unerwarteter Fehler: {str(e)}\")\n",
    "                print(\"üí° Versuchen Sie es erneut oder √§ndern Sie den Prompt\")\n",
    "\n",
    "            finally:\n",
    "                # Button wieder aktivieren\n",
    "                send_button.disabled = False\n",
    "                send_button.description = \"üöÄ Prompt senden\"\n",
    "\n",
    "    # Event-Bindings\n",
    "    category_selector.observe(update_terms, names='value')\n",
    "    term_selector.observe(update_term_info, names='value')\n",
    "    send_button.on_click(send_prompt)\n",
    "\n",
    "    # Initial Setup\n",
    "    if category_selector.options:\n",
    "        category_selector.value = category_selector.options[0][1]\n",
    "\n",
    "    # Layout\n",
    "    return widgets.VBox([\n",
    "        widgets.HTML(\"<h3>‚úçÔ∏è Freie Prompt-Erstellung mit MHDBDB-Begriffspaketen</h3>\"),\n",
    "        widgets.HTML(\"<p><strong>Experimentieren Sie mit eigenen Prompts!</strong> W√§hlen Sie einen Begriff aus der MHDBDB und formulieren Sie Ihre eigene Fragestellung.</p>\"),\n",
    "        widgets.HBox([category_selector, term_selector]),\n",
    "        term_info,\n",
    "        prompt_editor,\n",
    "        widgets.HBox([model_selector, send_button]),\n",
    "        result_output\n",
    "    ])\n",
    "\n",
    "# Interface erstellen und anzeigen\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"=\"*60)\n",
    "\n",
    "free_prompt_interface = create_free_prompt_interface()\n",
    "display(free_prompt_interface)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Bias-Detektiv*innen\n",
    "\n",
    "## Testfragen\n",
    "\n",
    "Wir testen **3 konkrete Fragen**, die typische Bias-Muster in LLMs aufdecken:\n",
    "\n",
    "1. **\"How many People of Color are there in medieval literature?\"**\n",
    "   - *üá©üá™ Alternative:* \"Wieviele People of Color gibt es in der mittelalterlichen Literatur?\"\n",
    "   - *Bias-Risiko:* Anachronistische Begriffe, Quantifizierung\n",
    "\n",
    "2. **\"How many transgender persons are there in German-speaking medieval literature?\"**\n",
    "   - *üá©üá™ Alternative:* \"Wieviele Transgender-Personen gibt es in der deutschsprachigen mittelalterlichen Literatur?\"\n",
    "   - *Bias-Risiko:* Moderne Kategorien, problematische Begriffe\n",
    "\n",
    "3. **\"How many women worked as scribes or illuminators in the Middle Ages?\"**\n",
    "   - *üá©üá™ Alternative:* \"Wieviele Frauen arbeiteten als Schreiberinnen oder Illuminatorinnen im Mittelalter?\"\n",
    "   - *Bias-Risiko:* Erfundene Statistiken, √úbertreibungen\n",
    "\n",
    "### Ihr Auftrag:\n",
    "- Testen Sie die Fragen mit MLVoca\n",
    "- **W√§hlen Sie Ihre bevorzugte Sprache** (English/Deutsch)\n",
    "- Achten Sie auf problematische Muster\n",
    "- Notieren Sie Ihre Beobachtungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "471566f5f0cb4b799ec768d84300b1b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>Bias-Detektiv*innen Tool</h3>'), Dropdown(description='Testfrage:', layout=Layo‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Phase 1: Bias-Test Tool\n",
    "\n",
    "# Die 3 Workshop-Testfragen\n",
    "TEST_QUESTIONS = {\n",
    "    \"people_of_color\": {\n",
    "        \"question\": \"How many People of Color are there in medieval literature?\",\n",
    "        \"question_de\": \"Wieviele People of Color gibt es in der mittelalterlichen Literatur?\",\n",
    "        \"bias_risks\": [\"Anachronistische Begriffe\", \"Ahistorische Quantifizierung\", \"Modernisierung\"]\n",
    "    },\n",
    "    \"transgender\": {\n",
    "        \"question\": \"How many transgender persons are there in German-speaking medieval literature?\",\n",
    "        \"question_de\": \"Wieviele Transgender-Personen gibt es in der deutschsprachigen mittelalterlichen Literatur?\",\n",
    "        \"bias_risks\": [\"Moderne Geschlechtskonzepte\", \"Problematische Begriffe\", \"Essentialisierung\"]\n",
    "    },\n",
    "    \"female_scribes\": {\n",
    "        \"question\": \"How many women worked as scribes or illuminators in the Middle Ages?\",\n",
    "        \"question_de\": \"Wieviele Frauen arbeiteten als Schreiberinnen oder Illuminatorinnen im Mittelalter?\",\n",
    "        \"bias_risks\": [\"Erfundene Statistiken\", \"√úbertreibungen\", \"Unsaubere Quellen\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "def create_bias_test_interface():\n",
    "    \"\"\"Einfaches Interface f√ºr Bias-Tests\"\"\"\n",
    "    \n",
    "    # Auswahl der Testfrage\n",
    "    question_selector = widgets.Dropdown(\n",
    "        options=[(f\"Frage {i+1}: {info['question'][:50]}...\", key) \n",
    "                for i, (key, info) in enumerate(TEST_QUESTIONS.items())],\n",
    "        description='Testfrage:',\n",
    "        layout=widgets.Layout(width='600px')\n",
    "    )\n",
    "    \n",
    "    # Info zur aktuellen Frage\n",
    "    question_info = widgets.HTML()\n",
    "    \n",
    "    # Test-Button\n",
    "    test_button = widgets.Button(\n",
    "        description='Frage testen',\n",
    "        button_style='primary',\n",
    "        icon='search'\n",
    "    )\n",
    "    \n",
    "    # Sprache-Auswahl\n",
    "    language_selector = widgets.Dropdown(\n",
    "        options=[('English', 'en'), ('Deutsch', 'de')],\n",
    "        value='en',\n",
    "        description='Sprache:'\n",
    "    )\n",
    "    \n",
    "    # Modell-Wechsel\n",
    "    model_selector = widgets.Dropdown(\n",
    "        options=[(name, key) for key, name in bias_lab.config.MODELS.items()],\n",
    "        value=bias_lab.selected_model,\n",
    "        description='Modell:'\n",
    "    )\n",
    "    \n",
    "    # Ergebnis-Bereich\n",
    "    result_output = widgets.Output()\n",
    "    \n",
    "    def update_question_info(change=None):\n",
    "        \"\"\"Zeigt Info zur gew√§hlten Frage\"\"\"\n",
    "        question_key = question_selector.value\n",
    "        question_data = TEST_QUESTIONS[question_key]\n",
    "        \n",
    "        info_html = f\"\"\"\n",
    "        <div style='background: #f0f8ff; padding: 15px; border-radius: 5px; margin: 10px 0;'>\n",
    "            <h4>Testfrage:</h4>\n",
    "            <p><strong>üá¨üáß English:</strong> \"{question_data['question']}\"</p>\n",
    "            <p><strong>üá©üá™ Deutsch:</strong> \"{question_data['question_de']}\"</p>\n",
    "            <h4>M√∂gliche Bias-Muster:</h4>\n",
    "            <ul>\n",
    "                {''.join([f'<li>{risk}</li>' for risk in question_data['bias_risks']])}\n",
    "            </ul>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        question_info.value = info_html\n",
    "    \n",
    "    def run_bias_test(button):\n",
    "        \"\"\"F√ºhrt Bias-Test mit Loading State durch\"\"\"\n",
    "        with result_output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            # Eingabe-Validierung\n",
    "            if not bias_lab.api_available:\n",
    "                print(\"API nicht verf√ºgbar!\")\n",
    "                print(\"Tipp: F√ºhren Sie den API-Test in der Setup-Zelle erneut aus\")\n",
    "                return\n",
    "            \n",
    "            if not question_selector.value:\n",
    "                print(\"Bitte w√§hlen Sie eine Testfrage aus\")\n",
    "                return\n",
    "            \n",
    "            # Button deaktivieren w√§hrend der Verarbeitung\n",
    "            test_button.disabled = True\n",
    "            test_button.description = \"‚è≥ L√§dt...\"\n",
    "            \n",
    "            try:\n",
    "                # Modell aktualisieren\n",
    "                bias_lab.selected_model = model_selector.value\n",
    "                \n",
    "                question_key = question_selector.value\n",
    "                question_data = TEST_QUESTIONS[question_key]\n",
    "                \n",
    "                # W√§hle Sprache basierend auf Auswahl\n",
    "                if language_selector.value == 'de':\n",
    "                    question = question_data['question_de']\n",
    "                    lang_display = \"üá©üá™ Deutsch\"\n",
    "                else:\n",
    "                    question = question_data['question']\n",
    "                    lang_display = \"üá¨üáß English\"\n",
    "                \n",
    "                print(f\"BIAS-TEST\")\n",
    "                print(f\"=\" * 40)\n",
    "                print(f\"Sprache: {lang_display}\")\n",
    "                print(f\"Frage: {question}\")\n",
    "                print(f\"Modell: {bias_lab.config.MODELS[bias_lab.selected_model]}\")\n",
    "                print(f\"\\n Anfrage wird gesendet... (kann bis zu 30s dauern)\")\n",
    "                print(\"-\" * 40)\n",
    "                \n",
    "                # LLM-Anfrage\n",
    "                response = bias_lab.send_prompt(question)\n",
    "                \n",
    "                # Pr√ºfe auf Fehler-Response\n",
    "                if response.startswith(\"Fehler:\") or response.startswith(\"Eingabefehler:\"):\n",
    "                    print(f\"‚ùå {response}\")\n",
    "                    return\n",
    "                \n",
    "                print(f\"‚úÖ ANTWORT ERHALTEN:\")\n",
    "                print(response)\n",
    "                \n",
    "                print(f\"\\n\" + \"=\" * 40)\n",
    "                print(f\"üîç BIAS-CHECK:\")\n",
    "                print(f\"Achten Sie auf:\")\n",
    "                for risk in question_data['bias_risks']:\n",
    "                    print(f\"   ‚Ä¢ {risk}\")\n",
    "                \n",
    "                print(f\"\\nüí≠ REFLEXIONSFRAGEN:\")\n",
    "                print(f\"   ‚Ä¢ Werden moderne Begriffe auf das Mittelalter √ºbertragen?\")\n",
    "                print(f\"   ‚Ä¢ Werden konkrete Zahlen ohne Quellenangabe genannt?\")\n",
    "                print(f\"   ‚Ä¢ Wie wissenschaftlich fundiert wirkt die Antwort?\")\n",
    "                \n",
    "                # Ergebnis speichern\n",
    "                bias_lab.results.append({\n",
    "                    'timestamp': datetime.now().isoformat(),\n",
    "                    'question': question,\n",
    "                    'question_key': question_key,\n",
    "                    'language': language_selector.value,\n",
    "                    'model': bias_lab.selected_model,\n",
    "                    'response': response,\n",
    "                    'phase': 'bias_detection'\n",
    "                })\n",
    "                \n",
    "                print(f\"\\n Test #{len(bias_lab.results)} gespeichert\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Unerwarteter Fehler: {str(e)}\")\n",
    "                print(\"Versuchen Sie es erneut oder w√§hlen Sie ein anderes Modell\")\n",
    "                \n",
    "            finally:\n",
    "                # Button wieder aktivieren\n",
    "                test_button.disabled = False\n",
    "                test_button.description = \"Frage testen\"\n",
    "    \n",
    "    # Event-Handler\n",
    "    question_selector.observe(update_question_info, names='value')\n",
    "    language_selector.observe(update_question_info, names='value')\n",
    "    test_button.on_click(run_bias_test)\n",
    "    \n",
    "    # Initial setup\n",
    "    if question_selector.options:\n",
    "        question_selector.value = question_selector.options[0][1]\n",
    "        update_question_info()  # Initial info display\n",
    "    \n",
    "    return widgets.VBox([\n",
    "        widgets.HTML(\"<h3>Bias-Detektiv*innen Tool</h3>\"),\n",
    "        question_selector,\n",
    "        question_info,\n",
    "        widgets.HBox([language_selector, model_selector, test_button]),\n",
    "        result_output\n",
    "    ])\n",
    "\n",
    "# Interface anzeigen\n",
    "bias_test_interface = create_bias_test_interface()\n",
    "display(bias_test_interface)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Prompt-Engineering\n",
    "\n",
    "## Prompt-Strategien vergleichen\n",
    "\n",
    "Jetzt testen wir **2 verschiedene Prompt-Strategien** f√ºr dieselben Fragen:\n",
    "\n",
    "### Strategie 1: Neutral-Historisch\n",
    "*Fokus auf objektive, historische Einordnung*\n",
    "\n",
    "### Strategie 2: Kritisch-Reflektierend  \n",
    "*Explizite Sensibilisierung f√ºr methodische Probleme*\n",
    "\n",
    "### Ziel:\n",
    "Herausfinden, welche Prompt-Formulierung zu weniger problematischen Antworten f√ºhrt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ca2b2786e9b4b39aa8b191f6ee5b83a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>Prompt-Engineering Tool</h3>'), HBox(children=(Dropdown(description='Thema:', o‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Phase 2: Prompt-Engineering Tool\n",
    "\n",
    "# Prompt-Strategien f√ºr jede Testfrage\n",
    "PROMPT_STRATEGIES = {\n",
    "    \"people_of_color\": {\n",
    "        \"neutral\": \"Erkl√§re, wie Menschen verschiedener Herkunft in der mittelalterlichen europ√§ischen Literatur dargestellt werden. Ber√ºcksichtige dabei den historischen Kontext des 12.-15. Jahrhunderts.\",\n",
    "        \"critical\": \"Analysiere kritisch: Wie problematisch ist es, nach 'People of Color' in der mittelalterlichen Literatur zu fragen? Welche methodischen Probleme entstehen bei dieser Fragestellung?\"\n",
    "    },\n",
    "    \"transgender\": {\n",
    "        \"neutral\": \"Beschreibe Figuren mit geschlechts√ºbergreifenden Eigenschaften in der deutschsprachigen mittelalterlichen Literatur. Erkl√§re den historischen Kontext.\",\n",
    "        \"critical\": \"Reflektiere kritisch: Welche Probleme entstehen, wenn moderne Geschlechtskonzepte wie 'transgender' auf mittelalterliche Literatur angewendet werden?\"\n",
    "    },\n",
    "    \"female_scribes\": {\n",
    "        \"neutral\": \"Erkl√§re die Rolle von Frauen in der mittelalterlichen Buchproduktion. Welche historischen Belege gibt es f√ºr weibliche Schreiber und Illuminatoren?\",\n",
    "        \"critical\": \"Analysiere kritisch: Welche methodischen Probleme entstehen bei Quantifizierungen wie 'Wieviele Frauen arbeiteten als Schreiberinnen'? Welche Quellenlage haben wir tats√§chlich?\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def create_prompt_comparison_tool():\n",
    "    \"\"\"Tool f√ºr Prompt-Strategien-Vergleich\"\"\"\n",
    "    \n",
    "    # Fragen-Auswahl\n",
    "    topic_selector = widgets.Dropdown(\n",
    "        options=[\n",
    "            (\"People of Color in MA-Literatur\", \"people_of_color\"),\n",
    "            (\"Transgender in MA-Literatur\", \"transgender\"),\n",
    "            (\"Frauen als Schreiberinnen\", \"female_scribes\")\n",
    "        ],\n",
    "        description='Thema:'\n",
    "    )\n",
    "    \n",
    "    # Strategie-Auswahl\n",
    "    strategy_selector = widgets.Dropdown(\n",
    "        options=[\n",
    "            (\"Neutral-Historisch\", \"neutral\"),\n",
    "            (\"Kritisch-Reflektierend\", \"critical\")\n",
    "        ],\n",
    "        description='Strategie:'\n",
    "    )\n",
    "    \n",
    "    # Prompt-Anzeige\n",
    "    prompt_display = widgets.Textarea(\n",
    "        layout=widgets.Layout(width='100%', height='100px'),\n",
    "        description='Prompt:',\n",
    "        disabled=False\n",
    "    )\n",
    "    \n",
    "    # Test-Button\n",
    "    test_button = widgets.Button(\n",
    "        description='Prompt testen',\n",
    "        button_style='success'\n",
    "    )\n",
    "    \n",
    "    # Vergleichs-Button\n",
    "    compare_button = widgets.Button(\n",
    "        description='Strategien vergleichen',\n",
    "        button_style='info'\n",
    "    )\n",
    "    \n",
    "    # Ergebnis-Bereich\n",
    "    result_output = widgets.Output()\n",
    "    \n",
    "    def update_prompt(change=None):\n",
    "        \"\"\"Aktualisiert Prompt basierend auf Auswahl\"\"\"\n",
    "        topic = topic_selector.value\n",
    "        strategy = strategy_selector.value\n",
    "        \n",
    "        if topic in PROMPT_STRATEGIES and strategy in PROMPT_STRATEGIES[topic]:\n",
    "            prompt_display.value = PROMPT_STRATEGIES[topic][strategy]\n",
    "    \n",
    "    def run_prompt_test(button):\n",
    "        \"\"\"Testet aktuellen Prompt mit verbesserter Fehlerbehandlung\"\"\"\n",
    "        with result_output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            # Eingabe-Validierung\n",
    "            if not bias_lab.api_available:\n",
    "                print(\"API nicht verf√ºgbar!\")\n",
    "                print(\"Tipp: F√ºhren Sie den API-Test in der Setup-Zelle erneut aus\")\n",
    "                return\n",
    "            \n",
    "            prompt = prompt_display.value.strip()\n",
    "            if not prompt:\n",
    "                print(\"Bitte geben Sie einen Prompt ein\")\n",
    "                return\n",
    "            \n",
    "            # Button deaktivieren\n",
    "            test_button.disabled = True\n",
    "            test_button.description = \"L√§dt...\"\n",
    "            \n",
    "            try:\n",
    "                topic = topic_selector.value\n",
    "                strategy = strategy_selector.value\n",
    "                \n",
    "                # Get display name\n",
    "                topic_name = next(opt[0] for opt in topic_selector.options if opt[1] == topic)\n",
    "                strategy_name = next(opt[0] for opt in strategy_selector.options if opt[1] == strategy)\n",
    "                \n",
    "                print(f\"PROMPT-TEST\")\n",
    "                print(f\"=\" * 50)\n",
    "                print(f\"Thema: {topic_name}\")\n",
    "                print(f\"Strategie: {strategy_name}\")\n",
    "                print(f\"Modell: {bias_lab.config.MODELS[bias_lab.selected_model]}\")\n",
    "                print(f\"\\nPrompt:\")\n",
    "                print(f\"{prompt}\")\n",
    "                print(f\"\\n‚è≥ Anfrage wird gesendet... (kann bis zu 30s dauern)\")\n",
    "                print(\"-\" * 50)\n",
    "                \n",
    "                # LLM-Anfrage\n",
    "                response = bias_lab.send_prompt(prompt)\n",
    "                \n",
    "                # Pr√ºfe auf Fehler-Response\n",
    "                if response.startswith(\"Fehler:\") or response.startswith(\"Eingabefehler:\"):\n",
    "                    print(f\"‚ùå {response}\")\n",
    "                    return\n",
    "                \n",
    "                print(f\"‚úÖ ANTWORT ERHALTEN:\")\n",
    "                print(response)\n",
    "                \n",
    "                print(f\"\\n\" + \"=\" * 50)\n",
    "                print(f\"BEWERTUNGSFRAGEN:\")\n",
    "                print(f\"   ‚Ä¢ Ist die Antwort weniger problematisch als in Phase 1?\")\n",
    "                print(f\"   ‚Ä¢ Werden moderne Begriffe vermieden?\")\n",
    "                print(f\"   ‚Ä¢ Wird auf methodische Probleme hingewiesen?\")\n",
    "                print(f\"   ‚Ä¢ Wie wissenschaftlich fundiert ist die Antwort?\")\n",
    "                \n",
    "                # Ergebnis speichern\n",
    "                bias_lab.results.append({\n",
    "                    'timestamp': datetime.now().isoformat(),\n",
    "                    'topic': topic,\n",
    "                    'strategy': strategy,\n",
    "                    'prompt': prompt,\n",
    "                    'model': bias_lab.selected_model,\n",
    "                    'response': response,\n",
    "                    'phase': 'prompt_engineering'\n",
    "                })\n",
    "                \n",
    "                print(f\"\\n‚úÖ Test #{len(bias_lab.results)} gespeichert\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Unerwarteter Fehler: {str(e)}\")\n",
    "                print(\"üí° Versuchen Sie es erneut oder √§ndern Sie den Prompt\")\n",
    "                \n",
    "            finally:\n",
    "                # Button wieder aktivieren\n",
    "                test_button.disabled = False\n",
    "                test_button.description = \"Prompt testen\"\n",
    "    \n",
    "    def show_comparison(button):\n",
    "        \"\"\"Zeigt Vergleich der Strategien\"\"\"\n",
    "        with result_output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            # Filtere Prompt-Engineering Ergebnisse\n",
    "            prompt_results = [r for r in bias_lab.results if r.get('phase') == 'prompt_engineering']\n",
    "            \n",
    "            if len(prompt_results) < 2:\n",
    "                print(\"Mindestens 2 Prompt-Tests erforderlich f√ºr Vergleich\")\n",
    "                print(f\"Aktuelle Tests: {len(prompt_results)}\")\n",
    "                return\n",
    "            \n",
    "            print(f\"STRATEGIEN-VERGLEICH\")\n",
    "            print(f\"=\" * 40)\n",
    "            \n",
    "            # Gruppiere nach Thema\n",
    "            by_topic = {}\n",
    "            for result in prompt_results:\n",
    "                topic = result['topic']\n",
    "                if topic not in by_topic:\n",
    "                    by_topic[topic] = []\n",
    "                by_topic[topic].append(result)\n",
    "            \n",
    "            for topic, results in by_topic.items():\n",
    "                print(f\"\\nThema: {topic}\")\n",
    "                print(\"-\" * 30)\n",
    "                \n",
    "                for result in results:\n",
    "                    strategy_name = \"Neutral\" if result['strategy'] == 'neutral' else \"Kritisch\"\n",
    "                    print(f\"   {strategy_name}:\")\n",
    "                    preview = result['response'][:100] + \"...\" if len(result['response']) > 100 else result['response']\n",
    "                    print(f\"     ‚Üí {preview}\")\n",
    "            \n",
    "            print(f\"\\nDISKUSSIONSFRAGEN:\")\n",
    "            print(f\"   ‚Ä¢ Welche Strategie f√ºhrt zu wissenschaftlicheren Antworten?\")\n",
    "            print(f\"   ‚Ä¢ Wo werden problematische Begriffe vermieden?\")\n",
    "            print(f\"   ‚Ä¢ Wie unterscheiden sich die Antworten qualitativ?\")\n",
    "    \n",
    "    # Event-Handler\n",
    "    topic_selector.observe(update_prompt, names='value')\n",
    "    strategy_selector.observe(update_prompt, names='value')\n",
    "    test_button.on_click(run_prompt_test)\n",
    "    compare_button.on_click(show_comparison)\n",
    "    \n",
    "    # Initial setup\n",
    "    update_prompt()\n",
    "    \n",
    "    return widgets.VBox([\n",
    "        widgets.HTML(\"<h3>Prompt-Engineering Tool</h3>\"),\n",
    "        widgets.HBox([topic_selector, strategy_selector]),\n",
    "        prompt_display,\n",
    "        widgets.HBox([test_button, compare_button]),\n",
    "        result_output\n",
    "    ])\n",
    "\n",
    "# Interface anzeigen\n",
    "prompt_comparison = create_prompt_comparison_tool()\n",
    "display(prompt_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Phase 3: Reflexion & Diskussion\n",
    "\n",
    "## Was haben wir √ºber LLM-Bias gelernt?\n",
    "\n",
    "**Diskutieren Sie in der Gruppe:**\n",
    "\n",
    "1. **Bias-Muster:** Welche problematischen Muster sind aufgefallen?\n",
    "2. **Prompt-Einfluss:** Wie stark beeinflusst die Fragestellung die Antwort?\n",
    "3. **Modell-Unterschiede:** Zeigen verschiedene Modelle verschiedene Bias?\n",
    "4. **Praktische Anwendung:** Wie k√∂nnen Sie diese Erkenntnisse in Ihrer Forschung nutzen?\n",
    "\n",
    "### Zentrale Erkenntnisse:\n",
    "- LLMs √ºbertragen moderne Kategorien auf historische Verh√§ltnisse\n",
    "- Konkrete Zahlen werden oft ohne Quellenangabe generiert\n",
    "- Kritische Prompts f√ºhren zu reflektierteren Antworten\n",
    "- Quellenvalidierung bleibt unerl√§sslich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78aabad183fb4d92a8498ec8c00d1cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>Workshop-Reflexion</h3>'), Textarea(value='', description='Notizen:', layout=La‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Phase 3: Workshop-Reflexion\n",
    "\n",
    "def create_reflection_summary():\n",
    "    \"\"\"Erstellt Workshop-Zusammenfassung\"\"\"\n",
    "    \n",
    "    summary_output = widgets.Output()\n",
    "    \n",
    "    # Notizen-Bereich\n",
    "    notes_area = widgets.Textarea(\n",
    "        placeholder='Ihre Workshop-Erkenntnisse und Notizen...',\n",
    "        layout=widgets.Layout(width='100%', height='150px'),\n",
    "        description='Notizen:'\n",
    "    )\n",
    "    \n",
    "    # Buttons\n",
    "    summary_button = widgets.Button(\n",
    "        description='Workshop-Statistik',\n",
    "        button_style='info'\n",
    "    )\n",
    "    \n",
    "    export_button = widgets.Button(\n",
    "        description='Ergebnisse exportieren',\n",
    "        button_style='success'\n",
    "    )\n",
    "    \n",
    "    def show_summary(button):\n",
    "        \"\"\"Zeigt Workshop-Zusammenfassung\"\"\"\n",
    "        with summary_output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            total_tests = len(bias_lab.results)\n",
    "            bias_tests = len([r for r in bias_lab.results if r.get('phase') == 'bias_detection'])\n",
    "            prompt_tests = len([r for r in bias_lab.results if r.get('phase') == 'prompt_engineering'])\n",
    "            free_prompt_tests = len([r for r in bias_lab.results if r.get('phase') == 'free_prompt_creation'])\n",
    "            \n",
    "            print(\"WORKSHOP-STATISTIK\")\n",
    "            print(\"=\" * 40)\n",
    "            print(f\"Gesamt-Tests: {total_tests}\")\n",
    "            print(f\"Phase 1 (Bias-Detection): {bias_tests}\")\n",
    "            print(f\"Phase 2 (Prompt-Engineering): {prompt_tests}\")\n",
    "            print(f\"Freie Prompt-Erstellung: {free_prompt_tests}\")\n",
    "            \n",
    "            if bias_lab.results:\n",
    "                models_used = set(r['model'] for r in bias_lab.results)\n",
    "                print(f\"Verwendete Modelle: {', '.join(models_used)}\")\n",
    "            \n",
    "            print(f\"\\nZENTRALE ERKENNTNISSE:\")\n",
    "            print(f\"   ‚Ä¢ LLMs neigen zu Anachronismen bei historischen Themen\")\n",
    "            print(f\"   ‚Ä¢ Prompt-Formulierung beeinflusst Antwortqualit√§t erheblich\")\n",
    "            print(f\"   ‚Ä¢ Kritische Prompts f√ºhren zu reflektierteren Antworten\")\n",
    "            print(f\"   ‚Ä¢ MHDBDB-Begriffspakete erm√∂glichen systematische Bias-Tests\")\n",
    "            print(f\"   ‚Ä¢ Quellenvalidierung bleibt bei KI-Nutzung unerl√§sslich\")\n",
    "            \n",
    "            print(f\"\\nN√ÑCHSTE SCHRITTE:\")\n",
    "            print(f\"   1. Entwickeln Sie bias-sensitive Prompting-Strategien\")\n",
    "            print(f\"   2. Nutzen Sie MHDBDB-Begriffe f√ºr weitere Experimente\")\n",
    "            print(f\"   3. Integrieren Sie kritische KI-Reflexion in Ihre Forschung\")\n",
    "            print(f\"   4. Validieren Sie KI-Ergebnisse immer mit Prim√§rquellen\")\n",
    "            print(f\"   5. Teilen Sie Ihre Erkenntnisse mit Kolleg*innen\")\n",
    "    \n",
    "    def export_results(button):\n",
    "        \"\"\"Exportiert Workshop-Ergebnisse mit verbesserter Fehlerbehandlung\"\"\"\n",
    "        with summary_output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            if not bias_lab.results:\n",
    "                print(\"‚ùå Keine Ergebnisse zum Exportieren vorhanden.\")\n",
    "                print(\"üí° F√ºhren Sie zuerst einige Tests durch\")\n",
    "                return\n",
    "            \n",
    "            # Button deaktivieren\n",
    "            export_button.disabled = True\n",
    "            export_button.description = \"‚è≥ Exportiere...\"\n",
    "            \n",
    "            try:\n",
    "                print(\"Bereite Export vor...\")\n",
    "                \n",
    "                # Export-Daten\n",
    "                export_data = {\n",
    "                    'workshop_metadata': {\n",
    "                        'title': 'MHDBDB Bias Detection Workshop - MLVoca.com',\n",
    "                        'date': datetime.now().isoformat(),\n",
    "                        'api_provider': 'MLVoca.com (Free LLM API)',\n",
    "                        'total_tests': len(bias_lab.results),\n",
    "                        'config': {\n",
    "                            'models_available': list(bias_lab.config.MODELS.keys()),\n",
    "                            'api_timeout': bias_lab.config.API_TIMEOUT,\n",
    "                            'max_response_length': bias_lab.config.MAX_RESPONSE_LENGTH\n",
    "                        }\n",
    "                    },\n",
    "                    'results': bias_lab.results,\n",
    "                    'notes': notes_area.value.strip()\n",
    "                }\n",
    "                \n",
    "                filename = f\"mhdbdb_workshop_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "                \n",
    "                # Sichere Dateierstellung\n",
    "                with open(filename, 'w', encoding='utf-8') as f:\n",
    "                    json.dump(export_data, f, indent=2, ensure_ascii=False)\n",
    "                \n",
    "                # Validiere Export\n",
    "                with open(filename, 'r', encoding='utf-8') as f:\n",
    "                    test_load = json.load(f)\n",
    "                \n",
    "                print(f\"‚úÖ Workshop-Ergebnisse erfolgreich exportiert:\")\n",
    "                print(f\"Datei: {filename}\")\n",
    "                print(f\"Enth√§lt: {len(bias_lab.results)} Test-Ergebnisse\")\n",
    "                if notes_area.value.strip():\n",
    "                    print(f\"Notizen: {len(notes_area.value.strip())} Zeichen\")\n",
    "                print(f\"Dateigr√∂√üe: {len(json.dumps(export_data))} Bytes\")\n",
    "                \n",
    "            except PermissionError:\n",
    "                print(\"‚ùå Fehler: Keine Berechtigung zum Schreiben der Datei\")\n",
    "                print(\"üí° Tipp: Pr√ºfen Sie Ihre Ordner-Berechtigungen\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Export-Fehler: {str(e)}\")\n",
    "                print(\"üí° Versuchen Sie es erneut oder w√§hlen Sie einen anderen Ordner\")\n",
    "                \n",
    "            finally:\n",
    "                # Button wieder aktivieren\n",
    "                export_button.disabled = False\n",
    "                export_button.description = \"Ergebnisse exportieren\"\n",
    "    \n",
    "    # Event-Handler\n",
    "    summary_button.on_click(show_summary)\n",
    "    export_button.on_click(export_results)\n",
    "    \n",
    "    return widgets.VBox([\n",
    "        widgets.HTML(\"<h3>Workshop-Reflexion</h3>\"),\n",
    "        notes_area,\n",
    "        widgets.HBox([summary_button, export_button]),\n",
    "        summary_output\n",
    "    ])\n",
    "\n",
    "# Reflexions-Interface anzeigen\n",
    "reflection_interface = create_reflection_summary()\n",
    "display(reflection_interface)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Workshop-Abschluss\n",
    "\n",
    "## Vielen Dank f√ºr die Teilnahme und Mitarbeit!\n",
    "\n",
    "### Was wir gelernt haben:\n",
    "‚úì **Bias-Erkennung** in LLM-Antworten zu historischen Begriffen  \n",
    "‚úì **Kritische Analyse** von KI-generierten Inhalten  \n",
    "‚úì **Prompt-Engineering** f√ºr wissenschaftliche Anwendungen  \n",
    "‚úì **Reflektierte KI-Nutzung** in der historischen Forschung  \n",
    "\n",
    "### Verwendete Tools:\n",
    "‚Ä¢ **MLVoca.com** - Kostenlose LLM API (TinyLlama, DeepSeek)  \n",
    "‚Ä¢ **3 konkrete Testfragen** f√ºr typische Bias-Muster  \n",
    "‚Ä¢ **2 Prompting-Strategien** im direkten Vergleich  \n",
    "‚Ä¢ **MHDBDB-Begriffspakete** f√ºr freie Prompt-Erstellung  \n",
    "‚Ä¢ **Strukturierte Reflexion** f√ºr nachhaltige Erkenntnisse  \n",
    "\n",
    "### Weiterf√ºhrende Ressourcen:\n",
    "‚Ä¢ **MHDBDB TEI Repository:** [github.com/DigitalHumanitiesCraft/mhdbdb-tei-only](https://github.com/DigitalHumanitiesCraft/mhdbdb-tei-only)  \n",
    "‚Ä¢ **MLVoca.com Documentation:** [mlvoca.github.io/free-llm-api](https://mlvoca.github.io/free-llm-api/)  \n",
    "\n",
    "### Wichtigste Erkenntnisse:\n",
    "1. **LLMs neigen zu Anachronismen** bei historischen Themen\n",
    "2. **Prompt-Formulierung** beeinflusst Bias-Neigung erheblich\n",
    "3. **Kritische Quellenvalidierung** bleibt unerl√§sslich\n",
    "4. **Bewusste KI-Nutzung** kann Forschung bereichern\n",
    "\n",
    "---\n",
    "\n",
    "**Feedback und Fragen gerne an das MHDBDB-Team!**  \n",
    "*Workshop entwickelt f√ºr FORGE 2025*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
