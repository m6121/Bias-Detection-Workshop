# ğŸŒ MHDBDB Workshop Deployment Guide

## Ãœbersicht: Drei Workshop-Optionen

Da das Repository **35+ MB** groÃŸ ist und alle Teilnehmer*innen das Notebook verwenden sollen, hier sind **3 praktische Alternativen**:

## ğŸ¥‡ **Option 1: Google Colab (Empfohlen fÃ¼r Workshops)**

### âœ… Vorteile:
- **Sofort einsatzbereit** - kein lokales Setup nÃ¶tig
- **Einheitliche Umgebung** fÃ¼r alle Teilnehmer*innen
- **Automatische Paket-Installation**
- **Eingebaute Download-Funktion** fÃ¼r Ergebnisse
- **Echte MHDBDB-Daten** embedded im Notebook

### ğŸ“‹ Setup:
1. **Notebook teilen**: 
   ```
   https://colab.research.google.com/github/your-repo/MHDBDB_Workshop_Colab.ipynb
   ```

2. **Teilnehmer*innen klicken**: 
   - "In Drive speichern" â†’ Eigene Kopie erstellen
   - Alle Zellen ausfÃ¼hren
   - Fertig!

### ğŸ“Š Enthaltene Daten:
- **19 echte MHDBDB-Begriffe** (vorprozessiert)
- **Aus authentischen mittelalterlichen Texten**
- **Mit Autorenzuschreibungen und Zeitangaben**

### ğŸ”§ Technische Details:
```python
# Workshop-Daten sind embedded:
mhdbdb_data = {
    "workshop_entries": [
        {"lemma": "saracÃ®n", "word": "sarazÃ®n", 
         "meaning": "AngehÃ¶riger eines islamischen Volkes", 
         "source_text": "Parzival", 
         "source_author": "Wolfram von Eschenbach"},
        # ... weitere 18 Begriffe
    ]
}
```

---

## ğŸ¥ˆ **Option 2: Vorprozessierte JSON-Datei**

### âœ… Vorteile:
- **Leichtgewichtig** (nur 12 KB statt 35 MB)
- **Schneller Download** fÃ¼r alle Teilnehmer*innen
- **Lokale Jupyter-Umgebung** nutzbar
- **VollstÃ¤ndige MHDBDB-Metadaten**

### ğŸ“‹ Setup:
1. **JSON-Datei bereitstellen**:
   - `mhdbdb_workshop_data.json` auf Server/Cloud hochladen
   - URL an Teilnehmer*innen verteilen

2. **Notebook anpassen**:
   ```python
   # Daten laden
   import requests
   data_url = "https://your-server.com/mhdbdb_workshop_data.json"
   response = requests.get(data_url)
   mhdbdb_data = response.json()
   ```

### ğŸ“Š Datenstruktur:
```json
{
  "metadata": {
    "source": "MHDBDB TEI Repository",
    "total_entries": 24,
    "unique_lemmata": 12
  },
  "workshop_entries": [...]
}
```

---

## ğŸ¥‰ **Option 3: Hybrid-LÃ¶sung (Binder/MyBinder)**

### âœ… Vorteile:
- **Kein Google-Account** nÃ¶tig
- **Repository-basiert** aber cloud-gehostet
- **VollstÃ¤ndige Kontrolle** Ã¼ber Umgebung

### ğŸ“‹ Setup:
1. **Repository vorbereiten**:
   ```
   your-workshop-repo/
   â”œâ”€â”€ MHDBDB_Workshop_Colab.ipynb
   â”œâ”€â”€ mhdbdb_workshop_data.json
   â”œâ”€â”€ requirements.txt
   â””â”€â”€ README.md
   ```

2. **Binder-Link generieren**:
   ```
   https://mybinder.org/v2/gh/your-username/workshop-repo/HEAD?filepath=MHDBDB_Workshop_Colab.ipynb
   ```

---

## ğŸ¯ **Empfehlung nach Workshop-GrÃ¶ÃŸe**

| Teilnehmer*innen | Empfohlene Option | Grund |
|------------------|-------------------|-------|
| **5-15** | Google Colab | Einfachstes Setup |
| **15-30** | JSON + lokales Jupyter | Weniger API-Kosten |
| **30+** | Binder + Mock-Daten | Keine externen Dependencies |

---

## ğŸ”§ **Technische Implementierung**

### Google Colab Notebook-Zellen:

#### Zelle 1: Setup
```python
# Automatische Paket-Installation
import subprocess
packages = ['openai', 'anthropic', 'ipywidgets']
for pkg in packages:
    subprocess.check_call(['pip', 'install', pkg, '-q'])
```

#### Zelle 2: Daten-Loading
```python
# Embedded MHDBDB-Daten (19 Begriffe)
mhdbdb_data = { ... }  # VollstÃ¤ndige Daten embedded
workshop_df = pd.DataFrame(mhdbdb_data["workshop_entries"])
```

#### Zelle 3: Workshop-Interface
```python
# Interaktive Begriff-Auswahl
term_dropdown = widgets.Dropdown(options=bias_options)
prompt_type_dropdown = widgets.Dropdown(options=prompt_types)
```

#### Zelle 4: Bias-Test-Execution
```python
# LLM-Integration mit Fallback zu Mock-Daten
def run_bias_test():
    # API-Calls oder Mock-Antworten
    # Automatische Bias-Pattern-Erkennung
    # Diskussionspunkte generieren
```

---

## ğŸ“ **Workshop-DurchfÃ¼hrung**

### â±ï¸ Zeitplan (90 Minuten):
1. **Setup** (5 min): Notebook Ã¶ffnen, Daten laden
2. **Exploration** (15 min): MHDBDB-Begriffe entdecken
3. **Bias-Detektiv*innen** (30 min): Problematische Aspekte identifizieren
4. **LLM-Experimente** (30 min): Verschiedene Prompts testen
5. **Analyse & Diskussion** (10 min): Ergebnisse besprechen

### ğŸ“ Lernziele:
- âœ… **Anachronismus-Erkennung**: Moderne Kategorien auf historische Begriffe
- âœ… **Quantifizierungs-Bias**: Unbelegte Zahlen in LLM-Antworten
- âœ… **Stereotype-Bewusstsein**: Vorurteile in KI-Systemen
- âœ… **Prompt-Engineering**: Bias-sensitive Fragestellungen

---

## ğŸš€ **Quick Start Guide**

### FÃ¼r Workshop-Leiter*innen:
1. **WÃ¤hlen Sie Option 1 (Google Colab)**
2. **Testen Sie das Notebook** selbst einmal durch
3. **Teilen Sie den Colab-Link** mit Teilnehmer*innen
4. **Bereiten Sie 2-3 API-Keys vor** (fÃ¼r Demos)

### FÃ¼r Teilnehmer*innen:
1. **Colab-Link Ã¶ffnen**
2. **"In Drive speichern" klicken**
3. **Alle Zellen ausfÃ¼hren** (Strg+F9)
4. **Workshop kann beginnen!**

---

## ğŸ”— **Ressourcen & Links**

- **Original MHDBDB**: https://github.com/DigitalHumanitiesCraft/mhdbdb-tei-only
- **Google Colab**: https://colab.research.google.com/
- **MyBinder**: https://mybinder.org/
- **OpenAI API**: https://platform.openai.com/api-keys
- **Anthropic API**: https://console.anthropic.com/

---

**ğŸ‰ Mit dieser Deployment-Strategie kÃ¶nnen Sie einen reibungslosen Workshop mit echten MHDBDB-Daten durchfÃ¼hren, ohne dass Teilnehmer*innen komplexe lokale Setups benÃ¶tigen!**

### ğŸ’¡ **Bonus-Tipp**: 
Erstellen Sie einen **Workshop-Workspace** in Google Drive und teilen Sie ihn mit allen Teilnehmer*innen. So haben alle Zugriff auf:
- Das Colab-Notebook
- ZusÃ¤tzliche Ressourcen
- Geteilte Ergebnisse 